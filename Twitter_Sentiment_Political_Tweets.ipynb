{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political Tweets Sentiment Analysis (SVM, Logistic Regression, Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys, os\n",
    "import string\n",
    "import re\n",
    "import datetime\n",
    "# Natural Language Processing\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer # load the stemmer module from NLTK\n",
    "dataloc = '/home/composersyf/Documents/Political Data Science Project/TwitterData'\n",
    "import emoji\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Components for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twtokenizer = TweetTokenizer()\n",
    "stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = list(set(string.punctuation)) + ['…','’','...','—',':/','”','..', '“']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should'] # Removed 'not','now', 'no','nor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Sentiment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_sample=pd.read_csv(\"/home/composersyf/Downloads/sentiment_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "training_index=random.sample(list(whole_sample[whole_sample.sentiment!='Neutral'].index),1000)\n",
    "validation_index=np.setdiff1d(range(whole_sample.shape[0]),training_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_sample=whole_sample.iloc[training_index,]\n",
    "validation_sample=whole_sample.iloc[validation_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Negative': 773, 'Positive': 227})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(training_sample.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_df=training_sample\n",
    "ads_df_cleaned=ads_df[ads_df.sentiment!='Neutral']\n",
    "ads_df_cleaned=ads_df_cleaned[~pd.isnull(ads_df_cleaned.Tweet)]\n",
    "ads_df_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    #tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "    cleanWords = twtokenizer.tokenize(tweet)\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    cleanWords = [t.lower() for t in cleanWords]\n",
    "    \n",
    "    # Convert Emoji's to Word Label\n",
    "    cleanWords = [emoji.demojize(word) for word in cleanWords]\n",
    "    \n",
    "    # Normalize (remove punctuation)\n",
    "    #Remove punctuation\n",
    "    cleanWords = [word for word in cleanWords if word not in punctuation]\n",
    "    \n",
    "    # punc = string.punctuation\n",
    "    # cleanWords = [t for t in cleanWords if t not in punc]\n",
    "    # cleanWords = [re.sub('[^0-9a-z]', \"\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove Empty Vectors\n",
    "    cleanWords = [x for x in cleanWords if x != '']\n",
    "     \n",
    "    # Remove StopWords\n",
    "    # cleanWords = [word for word in cleanWords if word not in stopwords_short]\n",
    "    cleanWords = [word for word in cleanWords if word not in stopwords]\n",
    "    \n",
    "    # Identify Digits & Convert to Num\n",
    "    #cleanWords = [re.sub(\"\\d+\", \"NUM\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove all Web/URL References\n",
    "    # Could be better to replace with 'URL'\n",
    "    cleanWords = [word for word in cleanWords if word[0:3] != 'htt']\n",
    "    \n",
    "    # Stem Words\n",
    "    cleanWords = [stemmer.stem(x) for x in cleanWords] # call stemmer to stem the input\n",
    "    \n",
    "    # Remove Multiple Letters, Replace with only 3\n",
    "    \n",
    "    return cleanWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ads_clean = [clean_tweets(ad) for ad in ads_df_cleaned['Tweet']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTermFreq(textList):\n",
    "    #calculate the term frequency for each text list\n",
    "    TF = {}\n",
    "    for row in textList:\n",
    "        #print(row)\n",
    "        for word in row:\n",
    "            # print(word)\n",
    "            if word in TF:\n",
    "                TF[word] += 1\n",
    "            else:\n",
    "                TF[word] = 1\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unigram Language Model\n",
    "def genUniLM(TF):\n",
    "    u_theta = pd.DataFrame.from_dict(TF, orient = \"index\")\n",
    "    u_theta.columns = ['TF']\n",
    "    # u_theta.sort('TF', ascending = False)[0:10]\n",
    "    # Total Number of Words in Training Corpus\n",
    "    nWords = u_theta['TF'].sum()\n",
    "    nWords\n",
    "    # Number of Unique Words in Training Corpus\n",
    "    vSize = len(u_theta['TF'])\n",
    "    vSize\n",
    "    # Calculate Probabilty of Each Word by TTF/N\n",
    "    u_theta['p'] = u_theta/nWords\n",
    "    u_theta = u_theta.sort_values('TF', ascending = False)\n",
    "    # Check that Probability Sums to 1\n",
    "    print(\"Total Probability: \",u_theta['p'].sum())\n",
    "    return u_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Term Frequency for All Negative Tweets\n",
    "#TF_neg = getTermFreq(neg_tweets_clean)\n",
    "#u_theta_neg = genUniLM(TF_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Term Frequency for All Positive Tweets\n",
    "#TF_pos = getTermFreq(pos_tweets_clean)\n",
    "#u_theta_pos = genUniLM(TF_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defind the functions to turn the corpus into document term matrix\n",
    "def create_countVectors(tokens):\n",
    "    doc_TF = {}\n",
    "    for token in tokens:\n",
    "        if token in doc_TF:\n",
    "            doc_TF[token] += 1\n",
    "        else:\n",
    "            doc_TF[token] = 1\n",
    "    return doc_TF\n",
    "\n",
    "def createDTM(corpus):\n",
    "    dtmHASH = {}\n",
    "    for key in corpus.keys():\n",
    "        dtmHASH[key] = create_countVectors(corpus[key])\n",
    "    return dtmHASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3393)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads_corpus={}\n",
    "for i,l in enumerate(ads_clean):\n",
    "    ads_corpus[i]=l\n",
    "ads_DTM=createDTM(ads_corpus)\n",
    "ads_df=pd.DataFrame.from_dict(ads_DTM, orient = 'index')\n",
    "ads_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ads_df=ads_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the terms whose term frequency is just 1\n",
    "# col_sums=ads_df.sum(axis=0)\n",
    "# ads_df_clean=ads_df.iloc[:,np.where(col_sums>1)[0]]\n",
    "# ads_df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3393"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of features present in the training set\n",
    "ads_df_clean=ads_df\n",
    "feature_names=ads_df_clean.columns.values\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Train an SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y=ads_df_cleaned.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Negative': 772, 'Positive': 228})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel=\"linear\",probability=True)\n",
    "svm_clf.fit(ads_df_clean,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a Logistic Regression (Maximum Entropy) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf=LogisticRegression(n_jobs=2)\n",
    "lr_clf.fit(ads_df_clean,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaludate the SVM & Logistic Regression model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#validation_sample=pd.read_csv(\"/home/composersyf/Downloads/sentiment_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_sample_text=validation_sample.Tweet\n",
    "validation_tweets_clean = [clean_tweets(tweet) for tweet in np.array(validation_sample_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194, 4117)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_tweets_corpus={}\n",
    "for i,l in enumerate(validation_tweets_clean):\n",
    "    validation_tweets_corpus[i]=l\n",
    "validation_tweets_DTM=createDTM(validation_tweets_corpus)\n",
    "validation_tweets_df=pd.DataFrame.from_dict(validation_tweets_DTM, orient = 'index')\n",
    "validation_tweets_df=validation_tweets_df.fillna(0)\n",
    "validation_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_part1=validation_tweets_df.loc[:,np.intersect1d(validation_tweets_df.columns.values,feature_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_part2=pd.DataFrame(np.zeros((1194,len(np.setdiff1d(feature_names,validation_tweets_df.columns.values)))))\n",
    "validation_tweets_df_part2.columns=np.setdiff1d(feature_names,validation_tweets_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_final=pd.concat([validation_tweets_df_part1,validation_tweets_df_part2],axis=1,join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names_before=validation_tweets_df_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_final=validation_tweets_df_final.loc[:,ads_df_clean.columns.values]\n",
    "column_names_after=validation_tweets_df_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(column_names_before)==len(column_names_after))\n",
    "print((column_names_before==column_names_after).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Negative': 282, 'Neutral': 824, 'Positive': 88})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from collections import Counter\n",
    "Counter(validation_sample.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Evaluate the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_pred=svm_clf.predict(validation_tweets_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_result=validation_sample.loc[:,['sentiment']]\n",
    "svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 73.51 %\n"
     ]
    }
   ],
   "source": [
    "svm_result_1=svm_result[svm_result.sentiment!='Neutral']\n",
    "c=0\n",
    "for i in range(svm_result_1.shape[0]):\n",
    "    if svm_result_1.sentiment.iloc[i]==svm_result_1.pred_sentiment.iloc[i]:\n",
    "        c+=1\n",
    "print('SVM Accuracy:',round(c*100/svm_result_1.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM imbalance (Positive rate): 15.4126213592233 %\n"
     ]
    }
   ],
   "source": [
    "svm_result_2=svm_result[svm_result.sentiment=='Neutral']\n",
    "print('SVM imbalance (Positive rate):', Counter(svm_result_2.pred_sentiment)['Positive']/svm_result_2.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[236,  46],\n",
       "       [ 52,  36]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svm_result_1.iloc[:,0],svm_result_1.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.92503118,  0.89767999,  0.46278617, ...,  0.75717166,\n",
       "        0.6773632 ,  0.79520843])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict_proba(validation_tweets_df_final)[:,0] #it's predicting the probability of negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold=[i*0.01+0.5 for i in range(51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.5\n",
      "SVM Accuracy: 76.76 %\n",
      "SVM imbalance (Positive rate): 4.733009708737864 %\n",
      "\n",
      "threshold:  0.51\n",
      "SVM Accuracy: 77.03 %\n",
      "SVM imbalance (Positive rate): 4.854368932038835 %\n",
      "\n",
      "threshold:  0.52\n",
      "SVM Accuracy: 77.57 %\n",
      "SVM imbalance (Positive rate): 5.097087378640777 %\n",
      "\n",
      "threshold:  0.53\n",
      "SVM Accuracy: 76.49 %\n",
      "SVM imbalance (Positive rate): 5.218446601941747 %\n",
      "\n",
      "threshold:  0.54\n",
      "SVM Accuracy: 76.76 %\n",
      "SVM imbalance (Positive rate): 6.432038834951456 %\n",
      "\n",
      "threshold:  0.55\n",
      "SVM Accuracy: 76.22 %\n",
      "SVM imbalance (Positive rate): 6.917475728155339 %\n",
      "\n",
      "threshold:  0.56\n",
      "SVM Accuracy: 76.49 %\n",
      "SVM imbalance (Positive rate): 7.524271844660194 %\n",
      "\n",
      "threshold:  0.5700000000000001\n",
      "SVM Accuracy: 76.49 %\n",
      "SVM imbalance (Positive rate): 7.8883495145631075 %\n",
      "\n",
      "threshold:  0.58\n",
      "SVM Accuracy: 75.68 %\n",
      "SVM imbalance (Positive rate): 8.13106796116505 %\n",
      "\n",
      "threshold:  0.59\n",
      "SVM Accuracy: 76.22 %\n",
      "SVM imbalance (Positive rate): 8.495145631067961 %\n",
      "\n",
      "threshold:  0.6\n",
      "SVM Accuracy: 77.03 %\n",
      "SVM imbalance (Positive rate): 8.980582524271846 %\n",
      "\n",
      "threshold:  0.61\n",
      "SVM Accuracy: 76.76 %\n",
      "SVM imbalance (Positive rate): 10.436893203883495 %\n",
      "\n",
      "threshold:  0.62\n",
      "SVM Accuracy: 76.49 %\n",
      "SVM imbalance (Positive rate): 11.04368932038835 %\n",
      "\n",
      "threshold:  0.63\n",
      "SVM Accuracy: 75.95 %\n",
      "SVM imbalance (Positive rate): 12.135922330097088 %\n",
      "\n",
      "threshold:  0.64\n",
      "SVM Accuracy: 75.14 %\n",
      "SVM imbalance (Positive rate): 12.742718446601941 %\n",
      "\n",
      "threshold:  0.65\n",
      "SVM Accuracy: 75.14 %\n",
      "SVM imbalance (Positive rate): 14.320388349514563 %\n",
      "\n",
      "threshold:  0.66\n",
      "SVM Accuracy: 73.51 %\n",
      "SVM imbalance (Positive rate): 15.291262135922329 %\n",
      "\n",
      "threshold:  0.67\n",
      "SVM Accuracy: 71.62 %\n",
      "SVM imbalance (Positive rate): 17.111650485436893 %\n",
      "\n",
      "threshold:  0.6799999999999999\n",
      "SVM Accuracy: 71.35 %\n",
      "SVM imbalance (Positive rate): 17.96116504854369 %\n",
      "\n",
      "threshold:  0.69\n",
      "SVM Accuracy: 71.08 %\n",
      "SVM imbalance (Positive rate): 19.174757281553397 %\n",
      "\n",
      "threshold:  0.7\n",
      "SVM Accuracy: 71.08 %\n",
      "SVM imbalance (Positive rate): 20.87378640776699 %\n",
      "\n",
      "threshold:  0.71\n",
      "SVM Accuracy: 71.08 %\n",
      "SVM imbalance (Positive rate): 22.330097087378643 %\n",
      "\n",
      "threshold:  0.72\n",
      "SVM Accuracy: 69.73 %\n",
      "SVM imbalance (Positive rate): 24.635922330097088 %\n",
      "\n",
      "threshold:  0.73\n",
      "SVM Accuracy: 69.73 %\n",
      "SVM imbalance (Positive rate): 26.699029126213592 %\n",
      "\n",
      "threshold:  0.74\n",
      "SVM Accuracy: 70.0 %\n",
      "SVM imbalance (Positive rate): 29.004854368932037 %\n",
      "\n",
      "threshold:  0.75\n",
      "SVM Accuracy: 68.92 %\n",
      "SVM imbalance (Positive rate): 31.79611650485437 %\n",
      "\n",
      "threshold:  0.76\n",
      "SVM Accuracy: 67.84 %\n",
      "SVM imbalance (Positive rate): 34.46601941747573 %\n",
      "[[197  85]\n",
      " [ 34  54]]\n",
      "\n",
      "threshold:  0.77\n",
      "SVM Accuracy: 67.03 %\n",
      "SVM imbalance (Positive rate): 36.16504854368932 %\n",
      "\n",
      "threshold:  0.78\n",
      "SVM Accuracy: 65.68 %\n",
      "SVM imbalance (Positive rate): 39.44174757281553 %\n",
      "\n",
      "threshold:  0.79\n",
      "SVM Accuracy: 62.97 %\n",
      "SVM imbalance (Positive rate): 41.74757281553398 %\n",
      "\n",
      "threshold:  0.8\n",
      "SVM Accuracy: 61.08 %\n",
      "SVM imbalance (Positive rate): 47.33009708737864 %\n",
      "\n",
      "threshold:  0.81\n",
      "SVM Accuracy: 58.92 %\n",
      "SVM imbalance (Positive rate): 50.728155339805824 %\n",
      "\n",
      "threshold:  0.8200000000000001\n",
      "SVM Accuracy: 54.59 %\n",
      "SVM imbalance (Positive rate): 53.51941747572816 %\n",
      "\n",
      "threshold:  0.8300000000000001\n",
      "SVM Accuracy: 52.16 %\n",
      "SVM imbalance (Positive rate): 57.88834951456311 %\n",
      "\n",
      "threshold:  0.8400000000000001\n",
      "SVM Accuracy: 49.73 %\n",
      "SVM imbalance (Positive rate): 64.44174757281553 %\n",
      "\n",
      "threshold:  0.8500000000000001\n",
      "SVM Accuracy: 45.95 %\n",
      "SVM imbalance (Positive rate): 69.53883495145631 %\n",
      "\n",
      "threshold:  0.86\n",
      "SVM Accuracy: 43.51 %\n",
      "SVM imbalance (Positive rate): 74.27184466019418 %\n",
      "\n",
      "threshold:  0.87\n",
      "SVM Accuracy: 41.35 %\n",
      "SVM imbalance (Positive rate): 78.39805825242718 %\n",
      "\n",
      "threshold:  0.88\n",
      "SVM Accuracy: 38.92 %\n",
      "SVM imbalance (Positive rate): 81.6747572815534 %\n",
      "\n",
      "threshold:  0.89\n",
      "SVM Accuracy: 37.03 %\n",
      "SVM imbalance (Positive rate): 84.5873786407767 %\n",
      "\n",
      "threshold:  0.9\n",
      "SVM Accuracy: 34.86 %\n",
      "SVM imbalance (Positive rate): 87.01456310679612 %\n",
      "\n",
      "threshold:  0.91\n",
      "SVM Accuracy: 32.7 %\n",
      "SVM imbalance (Positive rate): 90.77669902912622 %\n",
      "\n",
      "threshold:  0.9199999999999999\n",
      "SVM Accuracy: 31.62 %\n",
      "SVM imbalance (Positive rate): 92.59708737864078 %\n",
      "\n",
      "threshold:  0.9299999999999999\n",
      "SVM Accuracy: 28.92 %\n",
      "SVM imbalance (Positive rate): 94.66019417475728 %\n",
      "\n",
      "threshold:  0.94\n",
      "SVM Accuracy: 27.84 %\n",
      "SVM imbalance (Positive rate): 96.48058252427184 %\n",
      "\n",
      "threshold:  0.95\n",
      "SVM Accuracy: 26.76 %\n",
      "SVM imbalance (Positive rate): 97.57281553398059 %\n",
      "\n",
      "threshold:  0.96\n",
      "SVM Accuracy: 25.68 %\n",
      "SVM imbalance (Positive rate): 98.30097087378641 %\n",
      "\n",
      "threshold:  0.97\n",
      "SVM Accuracy: 25.14 %\n",
      "SVM imbalance (Positive rate): 99.51456310679612 %\n",
      "\n",
      "threshold:  0.98\n",
      "SVM Accuracy: 24.59 %\n",
      "SVM imbalance (Positive rate): 99.87864077669903 %\n",
      "\n",
      "threshold:  0.99\n",
      "SVM Accuracy: 23.78 %\n",
      "SVM imbalance (Positive rate): 100.0 %\n",
      "\n",
      "threshold:  1.0\n",
      "SVM Accuracy: 23.78 %\n",
      "SVM imbalance (Positive rate): 100.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_pred_prob=svm_clf.predict_proba(validation_tweets_df_final)[:,0]\n",
    "for t in threshold:\n",
    "    svm_result=validation_sample.loc[:,['sentiment']]\n",
    "    svm_result['pred_sentiment']=np.where(svm_pred_prob>t,\"Negative\",\"Positive\")\n",
    "    svm_result_1=svm_result[svm_result.sentiment!='Neutral']\n",
    "    print(\"threshold: \",t)\n",
    "    c=0\n",
    "    for i in range(svm_result_1.shape[0]):\n",
    "        if svm_result_1.sentiment.iloc[i]==svm_result_1.pred_sentiment.iloc[i]:\n",
    "            c+=1\n",
    "    print('SVM Accuracy:',round(c*100/svm_result_1.shape[0],2),'%')\n",
    "    svm_result_2=svm_result[svm_result.sentiment=='Neutral']\n",
    "    print('SVM imbalance (Positive rate):', Counter(svm_result_2.pred_sentiment)['Positive']/svm_result_2.shape[0]*100, '%')\n",
    "    if t==0.76:\n",
    "        print(confusion_matrix(svm_result_1.iloc[:,0],svm_result_1.iloc[:,1]))\n",
    "    print('')\n",
    "#svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "923"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(svm_pred_prob>0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### - Evaluate the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_pred=lr_clf.predict(validation_tweets_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_result=validation_sample.loc[:,['sentiment']]\n",
    "lr_result['pred_sentiment']=lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy: 77.57 %\n"
     ]
    }
   ],
   "source": [
    "lr_result_1=lr_result[lr_result.sentiment!='Neutral']\n",
    "c=0\n",
    "for i in range(lr_result_1.shape[0]):\n",
    "    if lr_result_1.sentiment.iloc[i]==lr_result_1.pred_sentiment.iloc[i]:\n",
    "        c+=1\n",
    "print('LR Accuracy:',round(c*100/lr_result_1.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR imbalance (Positive rate): 6.674757281553398 %\n"
     ]
    }
   ],
   "source": [
    "lr_result_2=lr_result[lr_result.sentiment=='Neutral']\n",
    "print('LR imbalance (Positive rate):', Counter(lr_result_2.pred_sentiment)['Positive']/lr_result_2.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[266,  16],\n",
       "       [ 67,  21]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lr_result_1.iloc[:,0],lr_result_1.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96727746,  0.94485916,  0.33299507, ...,  0.64509238,\n",
       "        0.55116502,  0.75444667])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict_proba(validation_tweets_df_final)[:,0] #it's predicting the probability of negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.5\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 6.674757281553398 %\n",
      "\n",
      "threshold:  0.51\n",
      "LR Accuracy: 77.84 %\n",
      "LR imbalance (Positive rate): 7.160194174757281 %\n",
      "\n",
      "threshold:  0.52\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 7.4029126213592225 %\n",
      "\n",
      "threshold:  0.53\n",
      "LR Accuracy: 77.03 %\n",
      "LR imbalance (Positive rate): 7.6456310679611645 %\n",
      "\n",
      "threshold:  0.54\n",
      "LR Accuracy: 77.03 %\n",
      "LR imbalance (Positive rate): 7.766990291262135 %\n",
      "\n",
      "threshold:  0.55\n",
      "LR Accuracy: 77.03 %\n",
      "LR imbalance (Positive rate): 8.13106796116505 %\n",
      "\n",
      "threshold:  0.56\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 8.859223300970873 %\n",
      "\n",
      "threshold:  0.5700000000000001\n",
      "LR Accuracy: 77.84 %\n",
      "LR imbalance (Positive rate): 9.70873786407767 %\n",
      "\n",
      "threshold:  0.58\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 10.194174757281553 %\n",
      "\n",
      "threshold:  0.59\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 10.679611650485436 %\n",
      "\n",
      "threshold:  0.6\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 11.407766990291263 %\n",
      "\n",
      "threshold:  0.61\n",
      "LR Accuracy: 77.3 %\n",
      "LR imbalance (Positive rate): 12.135922330097088 %\n",
      "\n",
      "threshold:  0.62\n",
      "LR Accuracy: 77.3 %\n",
      "LR imbalance (Positive rate): 12.985436893203882 %\n",
      "\n",
      "threshold:  0.63\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 13.834951456310678 %\n",
      "\n",
      "threshold:  0.64\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 14.441747572815533 %\n",
      "\n",
      "threshold:  0.65\n",
      "LR Accuracy: 77.3 %\n",
      "LR imbalance (Positive rate): 15.169902912621358 %\n",
      "\n",
      "threshold:  0.66\n",
      "LR Accuracy: 77.03 %\n",
      "LR imbalance (Positive rate): 15.655339805825244 %\n",
      "\n",
      "threshold:  0.67\n",
      "LR Accuracy: 76.76 %\n",
      "LR imbalance (Positive rate): 16.62621359223301 %\n",
      "\n",
      "threshold:  0.6799999999999999\n",
      "LR Accuracy: 76.76 %\n",
      "LR imbalance (Positive rate): 17.354368932038835 %\n",
      "\n",
      "threshold:  0.69\n",
      "LR Accuracy: 76.76 %\n",
      "LR imbalance (Positive rate): 18.203883495145632 %\n",
      "\n",
      "threshold:  0.7\n",
      "LR Accuracy: 77.03 %\n",
      "LR imbalance (Positive rate): 18.932038834951456 %\n",
      "\n",
      "threshold:  0.71\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 20.388349514563107 %\n",
      "\n",
      "threshold:  0.72\n",
      "LR Accuracy: 77.03 %\n",
      "LR imbalance (Positive rate): 21.601941747572813 %\n",
      "\n",
      "threshold:  0.73\n",
      "LR Accuracy: 78.11 %\n",
      "LR imbalance (Positive rate): 23.058252427184467 %\n",
      "\n",
      "threshold:  0.74\n",
      "LR Accuracy: 77.57 %\n",
      "LR imbalance (Positive rate): 24.271844660194176 %\n",
      "\n",
      "threshold:  0.75\n",
      "LR Accuracy: 76.22 %\n",
      "LR imbalance (Positive rate): 25.970873786407765 %\n",
      "\n",
      "threshold:  0.76\n",
      "LR Accuracy: 75.68 %\n",
      "LR imbalance (Positive rate): 28.033980582524272 %\n",
      "\n",
      "threshold:  0.77\n",
      "LR Accuracy: 73.51 %\n",
      "LR imbalance (Positive rate): 30.097087378640776 %\n",
      "\n",
      "threshold:  0.78\n",
      "LR Accuracy: 72.16 %\n",
      "LR imbalance (Positive rate): 31.55339805825243 %\n",
      "\n",
      "threshold:  0.79\n",
      "LR Accuracy: 69.73 %\n",
      "LR imbalance (Positive rate): 34.22330097087379 %\n",
      "\n",
      "threshold:  0.8\n",
      "LR Accuracy: 69.19 %\n",
      "LR imbalance (Positive rate): 35.92233009708738 %\n",
      "\n",
      "threshold:  0.81\n",
      "LR Accuracy: 68.11 %\n",
      "LR imbalance (Positive rate): 40.04854368932039 %\n",
      "\n",
      "threshold:  0.8200000000000001\n",
      "LR Accuracy: 67.03 %\n",
      "LR imbalance (Positive rate): 42.71844660194174 %\n",
      "\n",
      "threshold:  0.8300000000000001\n",
      "LR Accuracy: 66.22 %\n",
      "LR imbalance (Positive rate): 45.14563106796117 %\n",
      "\n",
      "threshold:  0.8400000000000001\n",
      "LR Accuracy: 65.41 %\n",
      "LR imbalance (Positive rate): 47.45145631067961 %\n",
      "[[176 106]\n",
      " [ 22  66]]\n",
      "\n",
      "threshold:  0.8500000000000001\n",
      "LR Accuracy: 63.24 %\n",
      "LR imbalance (Positive rate): 50.60679611650486 %\n",
      "\n",
      "threshold:  0.86\n",
      "LR Accuracy: 60.81 %\n",
      "LR imbalance (Positive rate): 53.883495145631066 %\n",
      "\n",
      "threshold:  0.87\n",
      "LR Accuracy: 58.65 %\n",
      "LR imbalance (Positive rate): 58.616504854368934 %\n",
      "\n",
      "threshold:  0.88\n",
      "LR Accuracy: 56.76 %\n",
      "LR imbalance (Positive rate): 63.228155339805824 %\n",
      "\n",
      "threshold:  0.89\n",
      "LR Accuracy: 53.78 %\n",
      "LR imbalance (Positive rate): 66.99029126213593 %\n",
      "\n",
      "threshold:  0.9\n",
      "LR Accuracy: 50.0 %\n",
      "LR imbalance (Positive rate): 71.48058252427184 %\n",
      "\n",
      "threshold:  0.91\n",
      "LR Accuracy: 45.68 %\n",
      "LR imbalance (Positive rate): 77.30582524271846 %\n",
      "\n",
      "threshold:  0.9199999999999999\n",
      "LR Accuracy: 41.62 %\n",
      "LR imbalance (Positive rate): 81.06796116504854 %\n",
      "\n",
      "threshold:  0.9299999999999999\n",
      "LR Accuracy: 38.11 %\n",
      "LR imbalance (Positive rate): 84.5873786407767 %\n",
      "\n",
      "threshold:  0.94\n",
      "LR Accuracy: 35.41 %\n",
      "LR imbalance (Positive rate): 88.22815533980582 %\n",
      "\n",
      "threshold:  0.95\n",
      "LR Accuracy: 33.51 %\n",
      "LR imbalance (Positive rate): 91.38349514563106 %\n",
      "\n",
      "threshold:  0.96\n",
      "LR Accuracy: 31.08 %\n",
      "LR imbalance (Positive rate): 94.78155339805825 %\n",
      "\n",
      "threshold:  0.97\n",
      "LR Accuracy: 27.03 %\n",
      "LR imbalance (Positive rate): 96.96601941747572 %\n",
      "\n",
      "threshold:  0.98\n",
      "LR Accuracy: 25.68 %\n",
      "LR imbalance (Positive rate): 98.54368932038835 %\n",
      "\n",
      "threshold:  0.99\n",
      "LR Accuracy: 24.86 %\n",
      "LR imbalance (Positive rate): 99.87864077669903 %\n",
      "\n",
      "threshold:  1.0\n",
      "LR Accuracy: 23.78 %\n",
      "LR imbalance (Positive rate): 100.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred_prob=lr_clf.predict_proba(validation_tweets_df_final)[:,0]\n",
    "for t in threshold:\n",
    "    lr_result=validation_sample.loc[:,['sentiment']]\n",
    "    lr_result['pred_sentiment']=np.where(lr_pred_prob>t,\"Negative\",\"Positive\")\n",
    "    lr_result_1=lr_result[lr_result.sentiment!='Neutral']\n",
    "    print(\"threshold: \",t)\n",
    "    c=0\n",
    "    for i in range(lr_result_1.shape[0]):\n",
    "        if lr_result_1.sentiment.iloc[i]==lr_result_1.pred_sentiment.iloc[i]:\n",
    "            c+=1\n",
    "    print('LR Accuracy:',round(c*100/lr_result_1.shape[0],2),'%')\n",
    "    lr_result_2=lr_result[lr_result.sentiment=='Neutral']\n",
    "    print('LR imbalance (Positive rate):', Counter(lr_result_2.pred_sentiment)['Positive']/lr_result_2.shape[0]*100, '%')\n",
    "    if round(t,2)==0.84:\n",
    "        print(confusion_matrix(lr_result_1.iloc[:,0],lr_result_1.iloc[:,1]))\n",
    "    print('')\n",
    "#svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Train a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit(ads_df_clean, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Evaluate the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_pred=nb_clf.predict(validation_tweets_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_result=validation_sample.loc[:,['sentiment']]\n",
    "nb_result['pred_sentiment']=nb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy: 76.22 %\n"
     ]
    }
   ],
   "source": [
    "nb_result_1=nb_result[nb_result.sentiment!='Neutral']\n",
    "c=0\n",
    "for i in range(nb_result_1.shape[0]):\n",
    "    if nb_result_1.sentiment.iloc[i]==nb_result_1.pred_sentiment.iloc[i]:\n",
    "        c+=1\n",
    "print('NB Accuracy:',round(c*100/nb_result_1.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB imbalance (Positive rate): 0.0 %\n"
     ]
    }
   ],
   "source": [
    "nb_result_2=nb_result[nb_result.sentiment=='Neutral']\n",
    "print('NB imbalance (Positive rate):', Counter(nb_result_2.pred_sentiment)['Positive']/nb_result_2.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[282,   0],\n",
       "       [ 88,   0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(nb_result_1.iloc[:,0],nb_result_1.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.9998\n",
      "NB Accuracy: 71.89 %\n",
      "NB imbalance (Positive rate): 26.57766990291262 %\n",
      "\n",
      "threshold:  0.999804\n",
      "NB Accuracy: 71.62 %\n",
      "NB imbalance (Positive rate): 27.063106796116504 %\n",
      "\n",
      "threshold:  0.999808\n",
      "NB Accuracy: 71.35 %\n",
      "NB imbalance (Positive rate): 27.548543689320386 %\n",
      "\n",
      "threshold:  0.999812\n",
      "NB Accuracy: 71.35 %\n",
      "NB imbalance (Positive rate): 27.669902912621357 %\n",
      "\n",
      "threshold:  0.999816\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 28.155339805825243 %\n",
      "\n",
      "threshold:  0.99982\n",
      "NB Accuracy: 70.81 %\n",
      "NB imbalance (Positive rate): 28.398058252427184 %\n",
      "\n",
      "threshold:  0.999824\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 28.640776699029125 %\n",
      "\n",
      "threshold:  0.999828\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 28.883495145631066 %\n",
      "\n",
      "threshold:  0.999832\n",
      "NB Accuracy: 70.81 %\n",
      "NB imbalance (Positive rate): 29.004854368932037 %\n",
      "\n",
      "threshold:  0.9998360000000001\n",
      "NB Accuracy: 70.81 %\n",
      "NB imbalance (Positive rate): 29.247572815533978 %\n",
      "\n",
      "threshold:  0.9998400000000001\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 29.36893203883495 %\n",
      "\n",
      "threshold:  0.9998440000000001\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 29.85436893203883 %\n",
      "\n",
      "threshold:  0.9998480000000001\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 29.975728155339805 %\n",
      "\n",
      "threshold:  0.9998520000000001\n",
      "NB Accuracy: 71.08 %\n",
      "NB imbalance (Positive rate): 30.097087378640776 %\n",
      "\n",
      "threshold:  0.999856\n",
      "NB Accuracy: 70.81 %\n",
      "NB imbalance (Positive rate): 30.339805825242717 %\n",
      "\n",
      "threshold:  0.99986\n",
      "NB Accuracy: 70.54 %\n",
      "NB imbalance (Positive rate): 30.461165048543688 %\n",
      "\n",
      "threshold:  0.999864\n",
      "NB Accuracy: 70.0 %\n",
      "NB imbalance (Positive rate): 30.70388349514563 %\n",
      "\n",
      "threshold:  0.999868\n",
      "NB Accuracy: 69.73 %\n",
      "NB imbalance (Positive rate): 31.43203883495146 %\n",
      "\n",
      "threshold:  0.999872\n",
      "NB Accuracy: 69.46 %\n",
      "NB imbalance (Positive rate): 31.6747572815534 %\n",
      "\n",
      "threshold:  0.999876\n",
      "NB Accuracy: 68.92 %\n",
      "NB imbalance (Positive rate): 32.28155339805826 %\n",
      "\n",
      "threshold:  0.99988\n",
      "NB Accuracy: 68.65 %\n",
      "NB imbalance (Positive rate): 32.5242718446602 %\n",
      "\n",
      "threshold:  0.999884\n",
      "NB Accuracy: 68.38 %\n",
      "NB imbalance (Positive rate): 33.25242718446602 %\n",
      "\n",
      "threshold:  0.999888\n",
      "NB Accuracy: 67.57 %\n",
      "NB imbalance (Positive rate): 33.980582524271846 %\n",
      "\n",
      "threshold:  0.999892\n",
      "NB Accuracy: 68.11 %\n",
      "NB imbalance (Positive rate): 34.101941747572816 %\n",
      "[[199  83]\n",
      " [ 35  53]]\n",
      "\n",
      "threshold:  0.999896\n",
      "NB Accuracy: 68.38 %\n",
      "NB imbalance (Positive rate): 34.83009708737864 %\n",
      "\n",
      "threshold:  0.9999\n",
      "NB Accuracy: 68.38 %\n",
      "NB imbalance (Positive rate): 35.43689320388349 %\n",
      "\n",
      "threshold:  0.999904\n",
      "NB Accuracy: 67.3 %\n",
      "NB imbalance (Positive rate): 35.43689320388349 %\n",
      "\n",
      "threshold:  0.999908\n",
      "NB Accuracy: 66.76 %\n",
      "NB imbalance (Positive rate): 35.80097087378641 %\n",
      "\n",
      "threshold:  0.999912\n",
      "NB Accuracy: 67.03 %\n",
      "NB imbalance (Positive rate): 36.16504854368932 %\n",
      "\n",
      "threshold:  0.999916\n",
      "NB Accuracy: 66.76 %\n",
      "NB imbalance (Positive rate): 37.13592233009709 %\n",
      "\n",
      "threshold:  0.99992\n",
      "NB Accuracy: 66.49 %\n",
      "NB imbalance (Positive rate): 37.86407766990291 %\n",
      "\n",
      "threshold:  0.999924\n",
      "NB Accuracy: 65.95 %\n",
      "NB imbalance (Positive rate): 38.349514563106794 %\n",
      "\n",
      "threshold:  0.999928\n",
      "NB Accuracy: 65.14 %\n",
      "NB imbalance (Positive rate): 39.19902912621359 %\n",
      "\n",
      "threshold:  0.999932\n",
      "NB Accuracy: 63.78 %\n",
      "NB imbalance (Positive rate): 39.92718446601942 %\n",
      "\n",
      "threshold:  0.999936\n",
      "NB Accuracy: 62.97 %\n",
      "NB imbalance (Positive rate): 40.16990291262136 %\n",
      "\n",
      "threshold:  0.99994\n",
      "NB Accuracy: 62.7 %\n",
      "NB imbalance (Positive rate): 41.74757281553398 %\n",
      "\n",
      "threshold:  0.999944\n",
      "NB Accuracy: 62.97 %\n",
      "NB imbalance (Positive rate): 42.71844660194174 %\n",
      "\n",
      "threshold:  0.9999480000000001\n",
      "NB Accuracy: 62.16 %\n",
      "NB imbalance (Positive rate): 43.810679611650485 %\n",
      "\n",
      "threshold:  0.9999520000000001\n",
      "NB Accuracy: 61.35 %\n",
      "NB imbalance (Positive rate): 44.66019417475729 %\n",
      "\n",
      "threshold:  0.9999560000000001\n",
      "NB Accuracy: 61.35 %\n",
      "NB imbalance (Positive rate): 46.359223300970875 %\n",
      "\n",
      "threshold:  0.9999600000000001\n",
      "NB Accuracy: 60.54 %\n",
      "NB imbalance (Positive rate): 48.907766990291265 %\n",
      "\n",
      "threshold:  0.9999640000000001\n",
      "NB Accuracy: 59.46 %\n",
      "NB imbalance (Positive rate): 51.213592233009706 %\n",
      "\n",
      "threshold:  0.999968\n",
      "NB Accuracy: 58.65 %\n",
      "NB imbalance (Positive rate): 52.79126213592234 %\n",
      "\n",
      "threshold:  0.999972\n",
      "NB Accuracy: 56.49 %\n",
      "NB imbalance (Positive rate): 55.33980582524271 %\n",
      "\n",
      "threshold:  0.999976\n",
      "NB Accuracy: 55.68 %\n",
      "NB imbalance (Positive rate): 57.28155339805825 %\n",
      "\n",
      "threshold:  0.99998\n",
      "NB Accuracy: 53.51 %\n",
      "NB imbalance (Positive rate): 60.43689320388349 %\n",
      "\n",
      "threshold:  0.999984\n",
      "NB Accuracy: 51.62 %\n",
      "NB imbalance (Positive rate): 64.92718446601941 %\n",
      "\n",
      "threshold:  0.999988\n",
      "NB Accuracy: 48.38 %\n",
      "NB imbalance (Positive rate): 69.1747572815534 %\n",
      "\n",
      "threshold:  0.999992\n",
      "NB Accuracy: 44.86 %\n",
      "NB imbalance (Positive rate): 77.30582524271846 %\n",
      "\n",
      "threshold:  0.999996\n",
      "NB Accuracy: 36.76 %\n",
      "NB imbalance (Positive rate): 87.86407766990291 %\n",
      "\n",
      "threshold:  1.0\n",
      "NB Accuracy: 23.78 %\n",
      "NB imbalance (Positive rate): 100.0 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold=[0.9998+0.000004*i for i in range(51)]\n",
    "nb_pred_prob=nb_clf.predict_proba(validation_tweets_df_final)[:,0]\n",
    "for t in threshold:\n",
    "    nb_result=validation_sample.loc[:,['sentiment']]\n",
    "    nb_result['pred_sentiment']=np.where(nb_pred_prob>t,\"Negative\",\"Positive\")\n",
    "    nb_result_1=nb_result[nb_result.sentiment!='Neutral']\n",
    "    print(\"threshold: \",t)\n",
    "    c=0\n",
    "    for i in range(nb_result_1.shape[0]):\n",
    "        if nb_result_1.sentiment.iloc[i]==nb_result_1.pred_sentiment.iloc[i]:\n",
    "            c+=1\n",
    "    print('NB Accuracy:',round(c*100/nb_result_1.shape[0],2),'%')\n",
    "    nb_result_2=nb_result[nb_result.sentiment=='Neutral']\n",
    "    print('NB imbalance (Positive rate):', Counter(nb_result_2.pred_sentiment)['Positive']/nb_result_2.shape[0]*100, '%')\n",
    "    if t==0.999892:\n",
    "        print(confusion_matrix(nb_result_1.iloc[:,0],nb_result_1.iloc[:,1]))\n",
    "    print('')\n",
    "#svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_sample.to_csv(\"sentiment_validation_training_part.csv\",index=False)\n",
    "validation_sample.to_csv(\"sentiment_validation_validation_part.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/composersyf/Documents/Political Data Science Project'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Term Freq for Whole Training Corpus, Maybe Filter Later (Cont = Controled Vocabulary)\n",
    "TF_cont = {}\n",
    "for word in set(list(TF_pos.keys())+list(TF_neg.keys())):\n",
    "    try: \n",
    "        p = TF_pos[word]\n",
    "    except KeyError: \n",
    "        p = 0\n",
    "    try: \n",
    "        n = TF_neg[word]\n",
    "    except KeyError: \n",
    "        n = 0\n",
    "    TF_cont[word] = p+n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampleKeys(TF_cont)\n",
    "TF_cont['love']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Estimate Naive Bayes classifier, Need to Smooth Before Implementation\n",
    "navBayes = {}\n",
    "for word in TF_cont:\n",
    "    try:\n",
    "        logRatio = math.log(u_theta_pos['p'].ix[word]/u_theta_neg['p'].ix[word])\n",
    "    except KeyError:\n",
    "        logRatio = 0\n",
    "    navBayes[word] = logRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:3: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "navBayesDF = pd.DataFrame.from_dict(navBayes, orient = \"index\")\n",
    "navBayesDF.columns = ['logRatio']\n",
    "navBayesDF = navBayesDF.sort('logRatio', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>:)</th>\n",
       "      <td>7.467538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bam</th>\n",
       "      <td>3.731222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>community</th>\n",
       "      <td>3.348230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goodnight</th>\n",
       "      <td>3.082526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrived</th>\n",
       "      <td>3.022807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glad</th>\n",
       "      <td>3.015085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appreciate</th>\n",
       "      <td>2.891471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opportunities</th>\n",
       "      <td>2.891471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loves</th>\n",
       "      <td>2.760443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>followers</th>\n",
       "      <td>2.719621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               logRatio\n",
       ":)             7.467538\n",
       "bam            3.731222\n",
       "community      3.348230\n",
       "goodnight      3.082526\n",
       "arrived        3.022807\n",
       "glad           3.015085\n",
       "appreciate     2.891471\n",
       "opportunities  2.891471\n",
       "loves          2.760443\n",
       "followers      2.719621"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "navBayesDF[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 0.5, 0.5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(neg_tweets_clean) + len(pos_tweets_clean)\n",
    "prob_neg = len(neg_tweets_clean)/total\n",
    "prob_pos = len(pos_tweets_clean)/total\n",
    "total, prob_pos, prob_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcfX_NBLin(tokenlist, prob1, prob0, pSmooth_1, pSmooth_0):\n",
    "    X = 0\n",
    "    for word in tokenlist:\n",
    "        try:\n",
    "            pX_y1 = pSmooth_1.ix[word]\n",
    "        except KeyError:\n",
    "            pX_y1 = 1\n",
    "        try:\n",
    "            pX_y0 = pSmooth_0.ix[word]\n",
    "        except KeyError:\n",
    "            pX_y0 = 1\n",
    "            \n",
    "        x = math.log(pX_y1)-math.log(pX_y0)\n",
    "        X = X + x\n",
    "    fX = math.log(prob1/prob0) + X\n",
    "\n",
    "    return fX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fX = [calcfX_NBLin(tweet, prob_pos, prob_neg, pSmooth_pos, pSmooth_neg) for tweet in tokenList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fx_sgn = [1 if tweet >= 0 else 0 for tweet in fX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53263"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model Against Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train to Find Junk Tweets? The ones I threw out bc were '@user @user2 URL' or other totally undisipherable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Validation Set\n",
    "HC_val = pd.read_csv('/Users/hopeemac/Documents/Code/GIT/Endorsements_Data/Twitter_Analysis/validation_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.4/site-packages/pandas/core/indexing.py:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>statusText</th>\n",
       "      <th>sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Tjaisb: @KrisParonto @HillaryClinton @13ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>#ICYMI: Confident @HillaryClinton tells @NYMag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @edvotes: How we treat educators matters. P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>RT @HillaryPix: #ImWithHer #HillaryClinton #Sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>@realDonaldTrump gave 100% collected funds to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Seize San Bernardino shooter insurance https:/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>RT @bfraser747: I've been asking myself everyd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>First: the @latimes. Now: @JerryBrownGov.  Her...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>@Forbes WHAT E-MAIL SCANDAL?. It is all going ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>@laughingliberal @Story27368218 @Occuping  I'm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>@HillaryClinton @BernieSanders Six days till H...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>RT @sivadavi8: #IObject to @HillaryClinton's W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>RT @ManMet80: We are a country of immigrants  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>RT @realitychek2015: Hey @jaketapper why don't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>RT @alexryanhannah: @realDonaldTrump knows how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>RT @bfraser747: I really do find you to be the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>RT @HillaryHoosiers: It's time to smash the ce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>RT @VABVOX: Except @HillaryClinton. Who will h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>RT @politico: A new California poll has @Hilla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>RT @AliceEngle3: @CNN @ABC @NBC @MSNBC @FOXNEW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>RT @3XT1: @HillaryClinton   But, racist @Hilla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>the first use of Mrs C playing the  #womancard...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>RT @sivadavi8: #IObject to @HillaryClinton's t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  Unnamed: 0                                         statusText sent\n",
       "0       1           1  RT @Tjaisb: @KrisParonto @HillaryClinton @13ho...    0\n",
       "1       2           2  #ICYMI: Confident @HillaryClinton tells @NYMag...    1\n",
       "2       4           4  RT @edvotes: How we treat educators matters. P...    1\n",
       "3      10          10  RT @HillaryPix: #ImWithHer #HillaryClinton #Sh...    1\n",
       "4      16          16  @realDonaldTrump gave 100% collected funds to ...    0\n",
       "5      17          17  Seize San Bernardino shooter insurance https:/...    0\n",
       "6      18          18  RT @bfraser747: I've been asking myself everyd...    0\n",
       "7      23          23  First: the @latimes. Now: @JerryBrownGov.  Her...    1\n",
       "8      24          24  @Forbes WHAT E-MAIL SCANDAL?. It is all going ...    1\n",
       "9      25          25  @laughingliberal @Story27368218 @Occuping  I'm...    0\n",
       "10     26          26  @HillaryClinton @BernieSanders Six days till H...    0\n",
       "11     27          27  RT @sivadavi8: #IObject to @HillaryClinton's W...    0\n",
       "12     29          29  RT @ManMet80: We are a country of immigrants  ...    1\n",
       "13     30          30  RT @realitychek2015: Hey @jaketapper why don't...    0\n",
       "14     31          31  RT @alexryanhannah: @realDonaldTrump knows how...    0\n",
       "15     33          33  RT @bfraser747: I really do find you to be the...    0\n",
       "16     39          39  RT @HillaryHoosiers: It's time to smash the ce...    1\n",
       "17     42          42  RT @VABVOX: Except @HillaryClinton. Who will h...    0\n",
       "18     43          43  RT @politico: A new California poll has @Hilla...    1\n",
       "19     45          45  RT @AliceEngle3: @CNN @ABC @NBC @MSNBC @FOXNEW...    0\n",
       "20     46          46  RT @3XT1: @HillaryClinton   But, racist @Hilla...    0\n",
       "21     47          47  the first use of Mrs C playing the  #womancard...    1\n",
       "22     50          50  RT @sivadavi8: #IObject to @HillaryClinton's t...    0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format Val Set\n",
    "HC_val_clean = HC_val.loc[HC_val.sent != 'X',:] # Removed \"unclear\" tweets\n",
    "\n",
    "HC_val_clean.loc[HC_val.sent == 'P','sent'] = 1 # Removed \"unclear\" tweets\n",
    "\n",
    "HC_val_clean.loc[HC_val.sent == 'N','sent'] = 0 # Removed \"unclear\" tweets\n",
    "HC_val_clean = HC_val_clean.reset_index()\n",
    "HC_val_clean\n",
    "# len(HC_val_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare Validation Ground Truth\n",
    "tokenList_HC_val = [clean_tweets(tweet) for tweet in HC_val_clean['statusText']]\n",
    "y_HC_val = [sent for sent in HC_val_clean['sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict Using Classifier\n",
    "fX = [calcfX_NBLin(tweet, prob_pos, prob_neg, pSmooth_pos, pSmooth_neg) for tweet in tokenList_HC_val]\n",
    "yHat_HC_val = [1 if tweet >= 0 else 0 for tweet in fX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57\n",
      "Precision: 0.46\n",
      "Recall: 0.67\n",
      "F1: 0.55\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %.2f' % accuracy_score(y_HC_val,yHat_HC_val))\n",
    "print('Precision: %.2f' % precision_score(y_HC_val,yHat_HC_val))\n",
    "print('Recall: %.2f' % recall_score(y_HC_val,yHat_HC_val))\n",
    "print('F1: %.2f' % f1_score(y_HC_val,yHat_HC_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Tjaisb: @KrisParonto @HillaryClinton @13hours How was your Memorial Day Hillery? Spend any of it with your family? https://t.co/mxJ2GkV… sentiment:  0 predicted:  1\n",
      "#ICYMI: Confident @HillaryClinton tells @NYMag: ‘We will win Texas’ https://t.co/laOkaoIQGc https://t.co/ZreiptVNJD sentiment:  1 predicted:  1\n",
      "RT @edvotes: How we treat educators matters. Presidential candidates should lead by example. @HillaryClinton #StrongPublicSchools https://t… sentiment:  1 predicted:  0\n",
      "RT @HillaryPix: #ImWithHer #HillaryClinton #ShesWithUs #BernieSanders #FeelTheBern #HRCIsOurNominee @HillaryClinton https://t.co/f47WeYJZ4y sentiment:  1 predicted:  1\n",
      "@realDonaldTrump gave 100% collected funds to Vets. @HillaryClinton 'charities' 10%, yes only 10%, out. Does #MSM report, do story? Shameful sentiment:  0 predicted:  1\n",
      "Seize San Bernardino shooter insurance https://t.co/Bt0lgSaJj5 @HillaryClinton ; Allow Benghazi victim families to sue Clinton Crime Fdn. sentiment:  0 predicted:  0\n",
      "RT @bfraser747: I've been asking myself everyday, what is wrong with these people who support @HillaryClinton Seriously ? #Trump2016 https:… sentiment:  0 predicted:  0\n",
      "First: the @latimes. Now: @JerryBrownGov.  Here's why Californians are voting for Hillary... https://t.co/TX4AQKvaJ4 via @HillaryClinton sentiment:  1 predicted:  1\n",
      "@Forbes WHAT E-MAIL SCANDAL?. It is all going well on all front of @HillaryClinton campaign. There is no scandal the Nominee Hil is cool sentiment:  1 predicted:  1\n",
      "@laughingliberal @Story27368218 @Occuping  I'm guessing those black lives don't matter so much ay, @HillaryClinton ? #Haiti #DropOutHillary sentiment:  0 predicted:  0\n",
      "@HillaryClinton @BernieSanders Six days till Hillary loses California. #FeelTheBern #FeelTheFraud #Cheatingisntwinning #RacketeeringHillary sentiment:  0 predicted:  0\n",
      "RT @sivadavi8: #IObject to @HillaryClinton's Wall Street speeches and the fact she will not #ReleaseTheTranscripts sentiment:  0 predicted:  0\n",
      "RT @ManMet80: We are a country of immigrants   #ImWithHer @HillaryClinton because she will beat Drumpf. #NeverTrump #UniteBlue 🇺🇸💙 https://… sentiment:  1 predicted:  0\n",
      "RT @realitychek2015: Hey @jaketapper why don't you & your ilk ever ask @HillaryClinton about where the $ donated to her \\charity\\\" goes? htt…\" sentiment:  0 predicted:  1\n",
      "RT @alexryanhannah: @realDonaldTrump knows how to create jobs and make money. @HillaryClinton only knows how to spend it. #MakeAmericaGreat… sentiment:  0 predicted:  1\n",
      "RT @bfraser747: I really do find you to be the most disgusting, evil, shameful person in politics  @HillaryClinton @TimAlexander429 https:/… sentiment:  0 predicted:  0\n",
      "RT @HillaryHoosiers: It's time to smash the ceiling. The USA needs @HillaryClinton. We can do this together. #ImWithHer #UniteBlue https://… sentiment:  1 predicted:  0\n",
      "RT @VABVOX: Except @HillaryClinton. Who will have a majority of \\real delegates\\\" on June 7 at 8:01pm EST when NJ polls close. https://t.co/…\" sentiment:  0 predicted:  0\n",
      "RT @politico: A new California poll has @HillaryClinton crushing @BernieSanders https://t.co/rLLUoAU5RV | AP Photo https://t.co/UnCYfYh08D sentiment:  1 predicted:  1\n",
      "RT @AliceEngle3: @CNN @ABC @NBC @MSNBC @FOXNEWS When will the media ask @HillaryClinton abt that missing 16 Million?    https://t.co/Yr3w1Z… sentiment:  0 predicted:  1\n",
      "RT @3XT1: @HillaryClinton   But, racist @HillaryClinton is complicit in the genocide of black people in #Libya.  | https://t.co/6aK9enW635 sentiment:  0 predicted:  1\n",
      "the first use of Mrs C playing the  #womancard may be my 14 April tweet https://t.co/icMCh9zWxQ @realDonaldTrump @HillaryClinton sentiment:  1 predicted:  1\n",
      "RT @sivadavi8: #IObject to @HillaryClinton's trade record https://t.co/2aINtWdLKS sentiment:  0 predicted:  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(HC_val_clean)):\n",
    "    print(HC_val_clean.loc[i,'statusText'], 'sentiment: ', HC_val_clean.loc[i,'sent'], 'predicted: ', yHat_HC_val[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum Pos/Neg Over Day Per Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_daily_sentiment(day, month, year):\n",
    "    print('Evaluating ',month,'/',day,'/',year)\n",
    "    fileList = pd.read_csv('masterFileList.csv')\n",
    "    HC_batch = fileList[(fileList['cleanCandidate'] == 'HillaryClinton') & (fileList['Year'] == year) \\\n",
    "                        & (fileList['Month'] == month) & (fileList['Day'] == day) & (fileList['Query'] == 'at')]\n",
    "    # Combine all @ Hillary Clinton Tweets for 1 Day\n",
    "    HC = pd.DataFrame()\n",
    "    for file in HC_batch.fileName:\n",
    "        print(file)\n",
    "        filePath =  dataloc + \"/\" + file\n",
    "        temp = readTwitterCSV(filePath)\n",
    "        # print(len(temp))\n",
    "        # print(len(temp.columns))\n",
    "        # print(temp.columns)\n",
    "        HC = pd.concat([HC,temp])\n",
    "    HC = HC.reset_index()\n",
    "    print('Number of Tweets: ', len(HC))\n",
    "    # Tokenize & Clean Corpus\n",
    "    tokenList = [clean_tweets(i) for i in HC['statusText']]\n",
    "    fX = [calcfX_NBLin(tweet, prob_pos, prob_neg, pSmooth_pos, pSmooth_neg) for tweet in tokenList]\n",
    "    yHat_HC_val = [1 if tweet >= 0 else 0 for tweet in fX]\n",
    "    HC['sent_predicted'] = yHat_HC_val\n",
    "    \n",
    "    # Sum Negative vs. Positive for the Day\n",
    "    pos_percent = sum(yHat_HC_val)/len(HC)\n",
    "    print('Positive: ', round(100*pos_percent,2),'%')\n",
    "    \n",
    "    return HC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating  5 / 31 / 2016\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.06.01.20\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.06.46.15\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.07.00.56\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.07.15.46\n",
      "Number of Tweets:  53263\n",
      "% Positive:  51.29 %\n"
     ]
    }
   ],
   "source": [
    "HC = get_daily_sentiment(31, 5, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readTwitterCSV(file):\n",
    "    data = pd.DataFrame(list(csv.reader(open(file),skipinitialspace=True)))\n",
    "    newCol = []\n",
    "    counter = 0\n",
    "    for word in data.iloc[0]:\n",
    "        if word is None:\n",
    "            word = 'None'+'_'+ str(counter)\n",
    "            newCol.append(word)\n",
    "            counter += 1\n",
    "        else:\n",
    "            newCol.append(word)\n",
    "    \n",
    "    data.columns = newCol\n",
    "    \n",
    "    data = data.drop(0)\n",
    "    data.dropna(axis = 0)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    #tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "    cleanWords = twtokenizer.tokenize(tweet)\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    cleanWords = [t.lower() for t in cleanWords]\n",
    "    \n",
    "    # Convert Emoji's to Word Label\n",
    "    cleanWords = [emoji.demojize(word) for word in cleanWords]\n",
    "    \n",
    "\n",
    "    # Normalize (remove punctuation)\n",
    "    #Remove punctuation\n",
    "    cleanWords = [word for word in cleanWords if word not in punctuation]\n",
    "    \n",
    "    # punc = string.punctuation\n",
    "    # cleanWords = [t for t in cleanWords if t not in punc]\n",
    "    # cleanWords = [re.sub('[^0-9a-z]', \"\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove Empty Vectors\n",
    "    cleanWords = [x for x in cleanWords if x != '']\n",
    "     \n",
    "    # Remove StopWords\n",
    "    # cleanWords = [word for word in cleanWords if word not in stopwords_short]\n",
    "    cleanWords = [word for word in cleanWords if word not in stopwords]\n",
    "    \n",
    "    # Identify Digits & Convert to Num\n",
    "    #cleanWords = [re.sub(\"\\d+\", \"NUM\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove all Web/URL References\n",
    "    # Could be better to replace with 'URL'\n",
    "    cleanWords = [word for word in cleanWords if word[0:3] != 'htt']\n",
    "    \n",
    "    # Stem Words\n",
    "    #cleanWords = [stemmer.stem(x) for x in cleanWords] # call stemmer to stem the input\n",
    "    \n",
    "    # Remove Multiple Letters, Replace with only 3\n",
    "    \n",
    "    \n",
    "    return cleanWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTermFreq(textList):\n",
    "    TF = {}\n",
    "    for row in textList:\n",
    "        #print(row)\n",
    "        for word in row:\n",
    "            # print(word)\n",
    "            if word in TF:\n",
    "                TF[word] += 1\n",
    "            else:\n",
    "                TF[word] = 1\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDocFreq(textlist):\n",
    "    DF = {}\n",
    "    for row in textlist:\n",
    "        for word in set(row):\n",
    "            # print(word)\n",
    "            if word in DF:\n",
    "                DF[word] += 1\n",
    "            else:\n",
    "                DF[word] = 1\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_countVectors(tokens):\n",
    "    doc_TF = {}\n",
    "    for token in tokens:\n",
    "        if token in doc_TF:\n",
    "            doc_TF[token] += 1\n",
    "        else:\n",
    "            doc_TF[token] = 1\n",
    "    return doc_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unigram Language Model\n",
    "def genUniLM(TF):\n",
    "    u_theta = pd.DataFrame.from_dict(TF, orient = \"index\")\n",
    "    u_theta.columns = ['TF']\n",
    "    # u_theta.sort('TF', ascending = False)[0:10]\n",
    "    # Total Number of Words in Training Corpus\n",
    "    nWords = u_theta['TF'].sum()\n",
    "    nWords\n",
    "    # Number of Unique Words in Training Corpus\n",
    "    vSize = len(u_theta['TF'])\n",
    "    vSize\n",
    "    # Calculate Probabilty of Each Word by TTF/N\n",
    "    u_theta['p'] = u_theta/nWords\n",
    "    u_theta = u_theta.sort('TF', ascending = False)\n",
    "    # Check that Probability Sums to 1\n",
    "    print(\"Total Probability: \",u_theta['p'].sum())\n",
    "    return u_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_pSmoothAdditive(tokenList, u_theta, d):\n",
    "    \n",
    "    vSize_train = len(u_theta)\n",
    "    nWords_train = sum(u_theta['TF'])\n",
    "    \n",
    "    unseenWords = list(set(tokenList) - set(u_theta.index))\n",
    "    #print(len(unseenWords))\n",
    "    if len(unseenWords) == 0:\n",
    "        return u_theta['p']\n",
    "    else:\n",
    "        # Build Series with all unique words in training set + unseen words from test document\n",
    "        pSmooth = u_theta['TF'].append(pd.Series(([0]*len(unseenWords)), index = unseenWords))\n",
    "        nWords_train += len(unseenWords)\n",
    "        vSize_train += len(unseenWords)\n",
    "        f = lambda x: ((x + d) / (nWords_train + d*vSize_train))\n",
    "        pSmooth = pSmooth.map(f)\n",
    "        return pSmooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampleKeys(dict):\n",
    "    return list(TF_neg.keys())[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build combined Pos/Neg Tweet Set with Labels (What about Neutral?)\n",
    "train = neg_tweets_clean + pos_tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.06.01.20\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.06.46.15\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.07.00.56\n",
      "[ BATCH -at,HillaryClinton-STATUS]2016.05.31.07.15.46\n"
     ]
    }
   ],
   "source": [
    "# Combine all @ Hillary Clinton Tweets for 1 Day\n",
    "HC = pd.DataFrame()\n",
    "for file in HC_batch.fileName:\n",
    "    print(file)\n",
    "    filePath =  dataloc + \"/\" + file\n",
    "    temp = readTwitterCSV(filePath)\n",
    "    # print(len(temp))\n",
    "    # print(len(temp.columns))\n",
    "    # print(temp.columns)\n",
    "    HC = pd.concat([HC,temp])\n",
    "HC = HC.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileList = pd.read_csv('masterFileList.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileList = pd.read_csv('masterFileList.csv')\n",
    "HC_batch = fileList[(fileList['cleanCandidate'] == 'HillaryClinton') & (fileList['Year'] == 2016) \\\n",
    "                    & (fileList['Month'] == 5) & (fileList['Day'] == 31) & (fileList['Query'] == 'at')]\n",
    "# Combine all @ Hillary Clinton Tweets for 1 Day\n",
    "HC = pd.DataFrame()\n",
    "for file in HC_batch.fileName:\n",
    "    print(file)\n",
    "    filePath =  dataloc + \"/\" + file\n",
    "    temp = readTwitterCSV(filePath)\n",
    "    # print(len(temp))\n",
    "    # print(len(temp.columns))\n",
    "    # print(temp.columns)\n",
    "    HC = pd.concat([HC,temp])\n",
    "HC = HC.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Adding Label to Each Tweet\n",
    "neg_tweets_labeled = list(zip(neg_tweets,['neg']*len(neg_tweets)))\n",
    "pos_tweets_labeled = list(zip(pos_tweets,['pos']*len(pos_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize & Clean Corpus\n",
    "tokenList = [clean_tweets(i) for i in HC['statusText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_unclean = getTermFreq(tokenList_unclean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TF_DF_unclean = pd.DataFrame.from_dict(TF_unclean, orient = 'index')\n",
    "TF_DF_unclean.columns = ['TF']\n",
    "TF_DF_unclean.sort_values(by = 'TF', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tokenize and Clean the Training Set [If using the NLTK, remove :( as a Feature)?]\n",
    "neg_tweets_clean = [(clean_tweets(tweet),sent) for (tweet,sent) in neg_tweets_labeled]\n",
    "pos_tweets_clean = [(clean_tweets(tweet),sent) for (tweet,sent) in pos_tweets_labeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TF_DF_unclean['Rank'] = range(1,len(TF_DF_unclean)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@HillaryClinton</th>\n",
       "      <td>73435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>55560</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>54143</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RT</th>\n",
       "      <td>44352</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>23262</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>21932</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>20945</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>16572</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>15144</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>14120</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TF  Rank\n",
       "@HillaryClinton  73435     1\n",
       ".                55560     2\n",
       ":                54143     3\n",
       "RT               44352     4\n",
       "the              23262     5\n",
       "to               21932     6\n",
       ",                20945     7\n",
       "of               16572     8\n",
       "!                15144     9\n",
       "is               14120    10"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_DF_unclean[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c4a9c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(TF_DF_unclean['Rank'],TF_DF_unclean['TF'], \n",
    "          color='darkblue', \n",
    "          linewidth = 2)\n",
    "plt.grid(True)\n",
    "plt.title(\"Zipf's Law - Twitter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEPCAYAAACukxSbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkf8PD6SjZm4h6UYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13f352e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.loglog(TF_DF_unclean['Rank'],TF_DF_unclean['TF'], \n",
    "          color='darkblue', \n",
    "          linewidth = 2)\n",
    "plt.grid(True)\n",
    "plt.title(\"Zipf's Law - Twitter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile(':.+:')\n",
    "if pattern.match(e):\n",
    "    print('emoji')\n",
    "#re.find(':.:',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['celebration',\n",
       " 'higher',\n",
       " '@awizardindallas',\n",
       " '1968',\n",
       " 'srop',\n",
       " 'bud',\n",
       " 'اعينكم',\n",
       " '#han',\n",
       " 'memers',\n",
       " '@shwahkram']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(TF.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF['high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get emoji counts\n",
    "TF_Emojis = {k:v for k, v in TF.items() if pattern.match(k)}\n",
    "# len(TF_XMore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TF_Emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove Stop Words (From 1-grams)\n",
    "def removeStopwords(text, stopwordList):\n",
    "    newList = [t for t in text if t not in stopwordList]\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topWords = pd.DataFrame.from_dict(TF_Emojis, orient = 'index')\n",
    "topWords.columns = ['TF']\n",
    "topWords.sort_values(ascending = False, inplace = True, by = 'TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>:face_with_tears_of_joy:</th>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:pistol:</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:heavy_black_heart:</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:clapping_hands_sign:</th>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:double_exclamation_mark:</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:party_popper:</th>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:blue_heart:</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:collision_symbol:</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:fire:</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:thumbs_up_sign:</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:white_right_pointing_backhand_index:</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:emoji_modifier_fitzpatrick_type-3:</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:money_bag:</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:grinning_face:</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:emoji_modifier_fitzpatrick_type-1-2:</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:emoji_modifier_fitzpatrick_type-4:</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:smiling_face_with_smiling_eyes:</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:ballot_box_with_check:</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:thinking_face:</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:white_left_pointing_backhand_index:</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:glowing_star:</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:pile_of_poo:</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:skull:</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:smiling_face_with_heart-shaped_eyes:</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:slightly_smiling_face:</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:high-heeled_shoe:</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:grinning_face_with_smiling_eyes:</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:pouting_face:</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:flushed_face:</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:imp:</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:woman:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:waving_hand_sign:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:honeybee:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:sleeping_symbol:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:lemon:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:crown:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:neutral_face:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:grimacing_face:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:sparkles:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:mouth:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:persevering_face:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:pill:</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:girl:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:tongue:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:put_litter_in_its_place_symbol:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:rat:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:dress:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:disappointed_but_relieved_face:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:black_question_mark_ornament:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:downwards_black_arrow:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:broken_heart:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:palm_tree:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:face_with_stuck-out_tongue_and_tightly-closed_eyes:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:bomb:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:four_leaf_clover:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:upside-down_face:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:kiss_mark:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:japanese_goblin:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:man:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:statue_of_liberty:</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     TF\n",
       ":face_with_tears_of_joy:                            533\n",
       ":pistol:                                            167\n",
       ":heavy_black_heart:                                 151\n",
       ":clapping_hands_sign:                               150\n",
       ":double_exclamation_mark:                           149\n",
       ":party_popper:                                      149\n",
       ":blue_heart:                                        143\n",
       ":collision_symbol:                                  135\n",
       ":fire:                                              135\n",
       ":thumbs_up_sign:                                    119\n",
       ":white_right_pointing_backhand_index:               106\n",
       ":emoji_modifier_fitzpatrick_type-3:                 104\n",
       ":money_bag:                                         101\n",
       ":grinning_face:                                      93\n",
       ":emoji_modifier_fitzpatrick_type-1-2:                89\n",
       ":emoji_modifier_fitzpatrick_type-4:                  84\n",
       ":smiling_face_with_smiling_eyes:                     79\n",
       ":ballot_box_with_check:                              75\n",
       ":thinking_face:                                      75\n",
       ":white_left_pointing_backhand_index:                 74\n",
       ":glowing_star:                                       69\n",
       ":pile_of_poo:                                        61\n",
       ":skull:                                              58\n",
       ":smiling_face_with_heart-shaped_eyes:                58\n",
       ":slightly_smiling_face:                              53\n",
       ":high-heeled_shoe:                                   51\n",
       ":grinning_face_with_smiling_eyes:                    51\n",
       ":pouting_face:                                       49\n",
       ":flushed_face:                                       49\n",
       ":imp:                                                49\n",
       "...                                                 ...\n",
       ":woman:                                               4\n",
       ":waving_hand_sign:                                    4\n",
       ":honeybee:                                            4\n",
       ":sleeping_symbol:                                     4\n",
       ":lemon:                                               4\n",
       ":crown:                                               4\n",
       ":neutral_face:                                        4\n",
       ":grimacing_face:                                      4\n",
       ":sparkles:                                            4\n",
       ":mouth:                                               4\n",
       ":persevering_face:                                    4\n",
       ":pill:                                                4\n",
       ":girl:                                                3\n",
       ":tongue:                                              3\n",
       ":put_litter_in_its_place_symbol:                      3\n",
       ":rat:                                                 3\n",
       ":dress:                                               3\n",
       ":disappointed_but_relieved_face:                      3\n",
       ":black_question_mark_ornament:                        3\n",
       ":downwards_black_arrow:                               3\n",
       ":broken_heart:                                        3\n",
       ":palm_tree:                                           3\n",
       ":face_with_stuck-out_tongue_and_tightly-closed_...    3\n",
       ":bomb:                                                3\n",
       ":four_leaf_clover:                                    3\n",
       ":upside-down_face:                                    3\n",
       ":kiss_mark:                                           3\n",
       ":japanese_goblin:                                     3\n",
       ":man:                                                 3\n",
       ":statue_of_liberty:                                   3\n",
       "\n",
       "[165 rows x 1 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topWords[topWords.TF > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'❓'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji.emojize(':black_question_mark_ornament:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Review Tweets Containing Specific Emoji\n",
    "emojiExamples = ]k:v for k, v in corpus.items() if emoji.emojize(':face_with_tears_of_joy:') in v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emojiExamples = [tweet for tweet in HC['statusText'] if emoji.emojize(':face_with_tears_of_joy:') in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@hillaryclinton',\n",
       " 'when',\n",
       " 'trump',\n",
       " \"isn't\",\n",
       " 'lying',\n",
       " 'on',\n",
       " 'natl',\n",
       " 'tv',\n",
       " 'or',\n",
       " 'at',\n",
       " 'rallies',\n",
       " 'he',\n",
       " 'likes',\n",
       " '2',\n",
       " 'talk',\n",
       " 'about',\n",
       " 'ratings',\n",
       " 'how',\n",
       " 'rich',\n",
       " 'he',\n",
       " 'is',\n",
       " 'and',\n",
       " 'how',\n",
       " 'much',\n",
       " 'he',\n",
       " 'loves',\n",
       " 'himself']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['737824642740555777']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36124"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TF.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14217"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Vocabulary w/ Over 20 Occurances\n",
    "TF_XMore = {k:v for k, v in TF.items() if v > 2}\n",
    "len(TF_XMore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topWords = pd.DataFrame.from_dict(TF_XMore, orient = 'index')\n",
    "topWords.columns = ['TF']\n",
    "topWords.sort_values(ascending = False, inplace = True, by = 'TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@hillaryclinton</th>\n",
       "      <td>74351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt</th>\n",
       "      <td>44358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>22669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>16956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>14953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>13086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>12403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@realdonaldtrump</th>\n",
       "      <td>10529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>10134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>9877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>7863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hillary</th>\n",
       "      <td>7182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>7035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>6285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>6244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>6237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what</th>\n",
       "      <td>5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>5685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>5392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>her</th>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>5082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>5073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@berniesanders</th>\n",
       "      <td>4816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@jerrybrowngov</th>\n",
       "      <td>4703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our</th>\n",
       "      <td>4650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>every</th>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>they're</th>\n",
       "      <td>963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interview</th>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>been</th>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@potus</th>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>around</th>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rest</th>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>here's</th>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#crookedhillary</th>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>via</th>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bernie</th>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>says</th>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>because</th>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>were</th>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proud</th>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poll</th>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forced</th>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you're</th>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trafficking</th>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crooked</th>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first-ever</th>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TF\n",
       "@hillaryclinton   74351\n",
       "rt                44358\n",
       "to                22669\n",
       "of                16956\n",
       "is                14953\n",
       "you               13086\n",
       "for               12403\n",
       "@realdonaldtrump  10529\n",
       "in                10134\n",
       "and                9877\n",
       "that               9234\n",
       "on                 8058\n",
       "i                  7863\n",
       "hillary            7182\n",
       "not                7035\n",
       "trump              6285\n",
       "it                 6244\n",
       "s                  6237\n",
       "be                 6087\n",
       "has                5859\n",
       "what               5764\n",
       "about              5685\n",
       "are                5392\n",
       "her                5233\n",
       "like               5082\n",
       "he                 5073\n",
       "we                 4918\n",
       "@berniesanders     4816\n",
       "@jerrybrowngov     4703\n",
       "our                4650\n",
       "...                 ...\n",
       "every               969\n",
       "they're             963\n",
       "interview           960\n",
       "been                955\n",
       "@potus              954\n",
       "around              951\n",
       "human               941\n",
       "rest                939\n",
       "here's              937\n",
       "#crookedhillary     930\n",
       "still               929\n",
       "via                 915\n",
       "go                  894\n",
       "bernie              892\n",
       "says                887\n",
       "day                 875\n",
       "make                875\n",
       "because             870\n",
       "most                865\n",
       "were                865\n",
       "ca                  857\n",
       "proud               854\n",
       "poll                851\n",
       "forced              849\n",
       "you're              847\n",
       "trafficking         843\n",
       "words               828\n",
       "campaign            819\n",
       "crooked             814\n",
       "first-ever          813\n",
       "\n",
       "[200 rows x 1 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topWords[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lda\n",
      "  Downloading lda-1.0.3-cp34-cp34m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (385kB)\n",
      "\u001b[K    100% |████████████████████████████████| 389kB 922kB/s \n",
      "\u001b[?25hCollecting pbr>=0.6 (from lda)\n",
      "  Downloading pbr-1.10.0-py2.py3-none-any.whl (96kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 5.2MB/s \n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): numpy<2.0,>=1.6.1 in /Applications/anaconda/lib/python3.4/site-packages (from lda)\n",
      "Installing collected packages: pbr, lda\n",
      "Successfully installed lda-1.0.3 pbr-1.10.0\n",
      "\u001b[33mYou are using pip version 8.0.3, however version 8.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lda.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to remove all words not in wordlist\n",
    "def keepWords(text, wordList):\n",
    "    newList = [t for t in text if t in wordList]\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter Vocabulary to Only Words w/ Greater than 5 Occurances (Removing Tail Words)\n",
    "TF = getTermFreq(tokenList)\n",
    "# Get Vocabulary w/ Over 5 Occurances\n",
    "TF_XMore = {k:v for k, v in TF.items() if v > 5}\n",
    "len(TF_XMore)\n",
    "words_XMore = list(TF_XMore.keys())\n",
    "tokenList = [keepWords(i, words_XMore) for i in tokenList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = {HC.loc[i,'statusId']: tokenList[i] for i in range(0,len(tokenList))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reuteres Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = lda.datasets.load_reuters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 4258)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = lda.datasets.load_reuters_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = lda.datasets.load_reuters_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: british churchill sale million major letters west britain\n",
      "Topic 1: church government political country state people party against\n",
      "Topic 2: elvis king fans presley life concert young death\n",
      "Topic 3: yeltsin russian russia president kremlin moscow michael operation\n",
      "Topic 4: pope vatican paul john surgery hospital pontiff rome\n",
      "Topic 5: family funeral police miami versace cunanan city service\n",
      "Topic 6: simpson former years court president wife south church\n",
      "Topic 7: order mother successor election nuns church nirmala head\n",
      "Topic 8: charles prince diana royal king queen parker bowles\n",
      "Topic 9: film french france against bardot paris poster animal\n",
      "Topic 10: germany german war nazi letter christian book jews\n",
      "Topic 11: east peace prize award timor quebec belo leader\n",
      "Topic 12: n't life show told very love television father\n",
      "Topic 13: years year time last church world people say\n",
      "Topic 14: mother teresa heart calcutta charity nun hospital missionaries\n",
      "Topic 15: city salonika capital buddhist cultural vietnam byzantine show\n",
      "Topic 16: music tour opera singer israel people film israeli\n",
      "Topic 17: church catholic bernardin cardinal bishop wright death cancer\n",
      "Topic 18: harriman clinton u.s ambassador paris president churchill france\n",
      "Topic 19: city museum art exhibition century million churches set\n",
      "0:00:48.606528\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)\n",
    "model.fit(X)  # model.fit_transform(X) is also available\n",
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ' '.join(topic_words)))\n",
    "runtime = datetime.datetime.now()-start\n",
    "print(str(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running w/ Political Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to Generate a Document-Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_countVectors(tokens):\n",
    "    doc_TF = {}\n",
    "    for token in tokens:\n",
    "        if token in doc_TF:\n",
    "            doc_TF[token] += 1\n",
    "        else:\n",
    "            doc_TF[token] = 1\n",
    "    return doc_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDTM(corpus):\n",
    "    dtmHASH = {}\n",
    "    for key in corpus.keys():\n",
    "        dtmHASH[key] = create_countVectors(corpus[key])\n",
    "    return dtmHASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm = createDTM(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the DTM to Matrix to Run in LDA Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm_df = pd.DataFrame.from_dict(dtm, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm_df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtm_df = dtm_df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm_matrix = dtm_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lda.LDA(n_topics=40, n_iter=1500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:16:06.887251\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "model.fit(dtm_matrix)  # model.fit_transform(X) is also available\n",
    "runtime = datetime.datetime.now()-start\n",
    "print(str(runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_word = model.topic_word_  # model.components_ also works\n",
    "n_top_words = 10\n",
    "vocab = dtm_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: @hillaryclinton, rt, hillary, #imwithher, not, go, stand, #caprimary, 10, 1992\n",
      "Topic 1: @hillaryclinton, rt, liar, one, not, lies, @neilturner_, she's, prison, please\n",
      "Topic 2: @hillaryclinton, rt, vote, record, still, trump, #imwithher, 🇸, 🇺, important\n",
      "Topic 3: trump, not, now, rt, even, he's, change, @hillaryclinton, climate, california\n",
      "Topic 4: @hillaryclinton, rt, @berniesanders, @jerrybrowngov, california, @politico, #feelthebern, #caprimary, #imwithher, new\n",
      "Topic 5: @hillaryclinton, rt, support, families, need, let's, give, words, service, deserve\n",
      "Topic 6: @hillaryclinton, rt, no, @fbi, @davidshuster, clinton, give, state, interview, not\n",
      "Topic 7: @hillaryclinton, benghazi, @realdonaldtrump, #benghazi, 4, rt, die, killed, don't, americans\n",
      "Topic 8: @hillaryclinton, don't, no, get, one, us, rt, think, right, time\n",
      "Topic 9: @hillaryclinton, rt, @berniesanders, email, allowed, it's, saying, democrats, see, ever\n",
      "Topic 10: @realdonaldtrump, war, rt, commander-in-chief, prisoners, @hillaryclinton, doesn't, like, wants, big\n",
      "Topic 11: @hillaryclinton, rt, @realdonaldtrump, h, @twright55, vote, support, done, @potus, @berniesanders\n",
      "Topic 12: @hillaryclinton, rt, @realdonaldtrump, poll, trump, @politico, she's, best, 2, beat\n",
      "Topic 13: @hillaryclinton, rt, #imwithher, care, veterans, #hillaryclinton, taking, part, americans, #sheswithus\n",
      "Topic 14: @hillaryclinton, rt, not, law, says, that's, could, #crookedhillary, get, america\n",
      "Topic 15: @hillaryclinton, rt, email, server, answer, @jaketapper, questions, chief, staff, watch\n",
      "Topic 16: @hillaryclinton, rt, de, trump, @jerrybrowngov, keep, no, going, don't, hillary\n",
      "Topic 17: @hillaryclinton, rt, @nrdc_af, proud, we're, fight, endorse, future, champion, who'll\n",
      "Topic 18: @hillaryclinton, rt, one, establishment, time, people, two, feel, #trump, serve\n",
      "Topic 19: @hillaryclinton, no, rt, vote, not, one, it's, people, time, america\n",
      "Topic 20: rt, @hillaryclinton, goldman, much, sachs, son-in-law, money, @theintercept, fund, ceo\n",
      "Topic 21: @hillaryclinton, rt, can't, world, millions, around, human, they're, rest, forced\n",
      "Topic 22: @hillaryclinton, @realdonaldtrump, vets, trump, much, money, @creynoldsnc, raised, veterans, foundation\n",
      "Topic 23: @hillaryclinton, rt, really, :face_with_tears_of_joy:, @rtraister, @realdonaldtrump, excellent, profile, @jessicavalenti, job\n",
      "Topic 24: like, people, @hillaryclinton, trump, say, rt, war, something, ok, captured\n",
      "Topic 25: @hillaryclinton, rt, @fbi, not, @davidshuster, @brianefallon, like, interview, making, easy\n",
      "Topic 26: @hillaryclinton, rt, @jerrybrowngov, brown, endorses, jerry, gov, california, ca, governor\n",
      "Topic 27: @hillaryclinton, rt, trump, president, donald, @realdonaldtrump, #imwithher, next, @potus, would\n",
      "Topic 28: @hillaryclinton, @berniesanders, not, rt, would, bernie, @msnbc, vote, country, cannot\n",
      "Topic 29: @hillaryclinton, rt, @realdonaldtrump, #trump2016, @bfraser747, #maga, @seanhannity, rigged, total, @billclinton\n",
      "Topic 30: @hillaryclinton, rt, american, day, endorsed, every, leadership, today, proud, caucus\n",
      "Topic 31: @hillaryclinton, rt, endorsement, @nrdc_af, presidential, first-ever, re, future, stake, makes\n",
      "Topic 32: @hillaryclinton, rt, like, @billclinton, @msnbc, @potus, sounds, @chrislhayes, mother, @bbhuttozardari\n",
      "Topic 33: @hillaryclinton, rt, @berniesanders, nominee, news, it's, @realdonaldtrump, needs, not, win\n",
      "Topic 34: @hillaryclinton, rt, not, you're, going, sorry, @berniesanders, corrupt, @sahilkapur, 4\n",
      "Topic 35: @hillaryclinton, u, @realdonaldtrump, 2, press, know, going, conference, r, don't\n",
      "Topic 36: hillary, @hillaryclinton, rt, know, see, never, you'll, rally, @jerrybrowngov, @latimes\n",
      "Topic 37: hillary, clinton, @hillaryclinton, rt, want, sure, office, takes, oath, @berniesanders\n",
      "Topic 38: @hillaryclinton, @cnn, @realdonaldtrump, ask, @msnbc, @jaketapper, media, @foxnews, tax, foundation\n",
      "Topic 39: @hillaryclinton, rt, caught, @jordanchariton, pro, not, @billdeblasio, @realdonaldtrump, that's, emails\n"
     ]
    }
   ],
   "source": [
    "# Print Top N Words in Each Topic\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    print('Topic {}: {}'.format(i, ', '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
