{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Political Tweets Sentiment Analysis (SVM, Logistic Regression, Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys, os\n",
    "import string\n",
    "import re\n",
    "import datetime\n",
    "# Natural Language Processing\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer # load the stemmer module from NLTK\n",
    "dataloc = '/home/composersyf/Documents/Political Data Science Project/TwitterData'\n",
    "import emoji\n",
    "# scikit-learn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Components for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twtokenizer = TweetTokenizer()\n",
    "stemmer=SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = list(set(string.punctuation)) + ['…','’','...','—',':/','”','..', '“']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    "'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    "'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    "'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    "'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    "'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    "'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    "'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    "'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    "'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so',\n",
    "'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should'] # Removed 'not','now', 'no','nor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Sentiment Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To download the Twitter Sentiment Files\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get ~ 10k Sentiment Labeled Tweets\n",
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "pos_tweets = twitter_samples.strings('positive_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    #tokenizer = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "    cleanWords = twtokenizer.tokenize(tweet)\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    cleanWords = [t.lower() for t in cleanWords]\n",
    "    \n",
    "    # Convert Emoji's to Word Label\n",
    "    cleanWords = [emoji.demojize(word) for word in cleanWords]\n",
    "    \n",
    "    # Normalize (remove punctuation)\n",
    "    #Remove punctuation\n",
    "    cleanWords = [word for word in cleanWords if word not in punctuation]\n",
    "    \n",
    "    # punc = string.punctuation\n",
    "    # cleanWords = [t for t in cleanWords if t not in punc]\n",
    "    # cleanWords = [re.sub('[^0-9a-z]', \"\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove Empty Vectors\n",
    "    cleanWords = [x for x in cleanWords if x != '']\n",
    "     \n",
    "    # Remove StopWords\n",
    "    # cleanWords = [word for word in cleanWords if word not in stopwords_short]\n",
    "    cleanWords = [word for word in cleanWords if word not in stopwords]\n",
    "    \n",
    "    # Identify Digits & Convert to Num\n",
    "    #cleanWords = [re.sub(\"\\d+\", \"NUM\", x) for x in cleanWords]\n",
    "    \n",
    "    # Remove all Web/URL References\n",
    "    # Could be better to replace with 'URL'\n",
    "    cleanWords = [word for word in cleanWords if word[0:3] != 'htt']\n",
    "    \n",
    "    # Stem Words\n",
    "    cleanWords = [stemmer.stem(x) for x in cleanWords] # call stemmer to stem the input\n",
    "    \n",
    "    # Remove Multiple Letters, Replace with only 3\n",
    "    \n",
    "    return cleanWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neg_tweets_clean = [clean_tweets(tweet) for tweet in neg_tweets]\n",
    "pos_tweets_clean = [clean_tweets(tweet) for tweet in pos_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: http://www.laurentluce.com/posts/twitter-sentiment-analysis-using-python-and-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTermFreq(textList):\n",
    "    #calculate the term frequency for each text list\n",
    "    TF = {}\n",
    "    for row in textList:\n",
    "        #print(row)\n",
    "        for word in row:\n",
    "            # print(word)\n",
    "            if word in TF:\n",
    "                TF[word] += 1\n",
    "            else:\n",
    "                TF[word] = 1\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unigram Language Model\n",
    "def genUniLM(TF):\n",
    "    u_theta = pd.DataFrame.from_dict(TF, orient = \"index\")\n",
    "    u_theta.columns = ['TF']\n",
    "    # u_theta.sort('TF', ascending = False)[0:10]\n",
    "    # Total Number of Words in Training Corpus\n",
    "    nWords = u_theta['TF'].sum()\n",
    "    nWords\n",
    "    # Number of Unique Words in Training Corpus\n",
    "    vSize = len(u_theta['TF'])\n",
    "    vSize\n",
    "    # Calculate Probabilty of Each Word by TTF/N\n",
    "    u_theta['p'] = u_theta/nWords\n",
    "    u_theta = u_theta.sort_values('TF', ascending = False)\n",
    "    # Check that Probability Sums to 1\n",
    "    print(\"Total Probability: \",u_theta['p'].sum())\n",
    "    return u_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Term Frequency for All Negative Tweets\n",
    "#TF_neg = getTermFreq(neg_tweets_clean)\n",
    "#u_theta_neg = genUniLM(TF_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Term Frequency for All Positive Tweets\n",
    "#TF_pos = getTermFreq(pos_tweets_clean)\n",
    "#u_theta_pos = genUniLM(TF_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defind the functions to turn the corpus into document term matrix\n",
    "def create_countVectors(tokens):\n",
    "    doc_TF = {}\n",
    "    for token in tokens:\n",
    "        if token in doc_TF:\n",
    "            doc_TF[token] += 1\n",
    "        else:\n",
    "            doc_TF[token] = 1\n",
    "    return doc_TF\n",
    "\n",
    "def createDTM(corpus):\n",
    "    dtmHASH = {}\n",
    "    for key in corpus.keys():\n",
    "        dtmHASH[key] = create_countVectors(corpus[key])\n",
    "    return dtmHASH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 9312)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets_corpus={}\n",
    "for i,l in enumerate(neg_tweets_clean):\n",
    "    neg_tweets_corpus[i]=l\n",
    "neg_tweets_DTM=createDTM(neg_tweets_corpus)\n",
    "neg_tweets_df=pd.DataFrame.from_dict(neg_tweets_DTM, orient = 'index')\n",
    "neg_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 11346)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tweets_corpus={}\n",
    "for i,l in enumerate(pos_tweets_clean):\n",
    "    pos_tweets_corpus[i]=l\n",
    "pos_tweets_DTM=createDTM(pos_tweets_corpus)\n",
    "pos_tweets_df=pd.DataFrame.from_dict(pos_tweets_DTM, orient = 'index')\n",
    "pos_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 17890)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack the positive DTM and negative DTM together vertically\n",
    "tweets_df=pd.concat([pos_tweets_df,neg_tweets_df],join=\"outer\",axis=0)\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace the NA values with zero\n",
    "tweets_df=tweets_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4652)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the terms whose term frequency is just 1\n",
    "col_sums=tweets_df.sum(axis=0)\n",
    "tweets_df_clean=tweets_df.iloc[:,np.where(col_sums>1)[0]]\n",
    "tweets_df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4652"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of features present in the training set\n",
    "feature_names=tweets_df_clean.columns.values\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Train an SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=[\"Positive\"]*5000+[\"Negative\"]*5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf=svm.SVC(kernel=\"linear\",probability=True)\n",
    "svm_clf.fit(tweets_df_clean,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Train a Logistic Regression (Maximum Entropy) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=2,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf=LogisticRegression(n_jobs=2)\n",
    "lr_clf.fit(tweets_df_clean,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaludate the SVM & Logistic Regression model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_sample=pd.read_csv(\"/home/composersyf/Downloads/sentiment_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_sample_text=validation_sample.Tweet\n",
    "validation_tweets_clean = [clean_tweets(tweet) for tweet in np.array(validation_sample_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2194, 5994)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_tweets_corpus={}\n",
    "for i,l in enumerate(validation_tweets_clean):\n",
    "    validation_tweets_corpus[i]=l\n",
    "validation_tweets_DTM=createDTM(validation_tweets_corpus)\n",
    "validation_tweets_df=pd.DataFrame.from_dict(validation_tweets_DTM, orient = 'index')\n",
    "validation_tweets_df=validation_tweets_df.fillna(0)\n",
    "validation_tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_part1=validation_tweets_df.loc[:,np.intersect1d(validation_tweets_df.columns.values,feature_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_part2=pd.DataFrame(np.zeros((2194,len(np.setdiff1d(feature_names,validation_tweets_df.columns.values)))))\n",
    "validation_tweets_df_part2.columns=np.setdiff1d(feature_names,validation_tweets_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_final=pd.concat([validation_tweets_df_part1,validation_tweets_df_part2],axis=1,join=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_names_before=validation_tweets_df_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_tweets_df_final=validation_tweets_df_final.loc[:,tweets_df_clean.columns.values]\n",
    "column_names_after=validation_tweets_df_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(column_names_before)==len(column_names_after))\n",
    "print((column_names_before==column_names_after).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Negative': 1054, 'Neutral': 824, 'Positive': 316})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(validation_sample.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Evaluate the SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_pred=svm_clf.predict(validation_tweets_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_result=validation_sample.loc[:,['sentiment']]\n",
    "svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 62.12 %\n"
     ]
    }
   ],
   "source": [
    "svm_result_1=svm_result[svm_result.sentiment!='Neutral']\n",
    "c=0\n",
    "for i in range(svm_result_1.shape[0]):\n",
    "    if svm_result_1.sentiment.iloc[i]==svm_result_1.pred_sentiment.iloc[i]:\n",
    "        c+=1\n",
    "print('SVM Accuracy:',round(c*100/svm_result_1.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[736, 318],\n",
       "       [201, 115]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(svm_result_1.iloc[:,0],svm_result_1.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM imbalance (Positive rate): 28.398058252427184 %\n"
     ]
    }
   ],
   "source": [
    "svm_result_2=svm_result[svm_result.sentiment=='Neutral']\n",
    "print('SVM imbalance (Positive rate):', Counter(svm_result_2.pred_sentiment)['Positive']/svm_result_2.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00949859,  0.12273114,  0.77612369, ...,  0.79343947,\n",
       "        0.75273737,  0.94003868])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict_proba(validation_tweets_df_final)[:,0] #it's predicting the probability of negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold=[i*0.01+0 for i in range(51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.0\n",
      "SVM Accuracy: 76.93 %\n",
      "SVM imbalance (Positive rate): 0.0 %\n",
      "\n",
      "threshold:  0.01\n",
      "SVM Accuracy: 76.93 %\n",
      "SVM imbalance (Positive rate): 0.3640776699029126 %\n",
      "\n",
      "threshold:  0.02\n",
      "SVM Accuracy: 76.72 %\n",
      "SVM imbalance (Positive rate): 0.8495145631067961 %\n",
      "\n",
      "threshold:  0.03\n",
      "SVM Accuracy: 76.06 %\n",
      "SVM imbalance (Positive rate): 1.3349514563106795 %\n",
      "\n",
      "threshold:  0.04\n",
      "SVM Accuracy: 75.91 %\n",
      "SVM imbalance (Positive rate): 1.9417475728155338 %\n",
      "\n",
      "threshold:  0.05\n",
      "SVM Accuracy: 75.91 %\n",
      "SVM imbalance (Positive rate): 2.063106796116505 %\n",
      "\n",
      "threshold:  0.06\n",
      "SVM Accuracy: 75.84 %\n",
      "SVM imbalance (Positive rate): 2.3058252427184467 %\n",
      "\n",
      "threshold:  0.07\n",
      "SVM Accuracy: 75.77 %\n",
      "SVM imbalance (Positive rate): 3.1553398058252426 %\n",
      "\n",
      "threshold:  0.08\n",
      "SVM Accuracy: 75.47 %\n",
      "SVM imbalance (Positive rate): 3.3980582524271843 %\n",
      "\n",
      "threshold:  0.09\n",
      "SVM Accuracy: 75.26 %\n",
      "SVM imbalance (Positive rate): 3.640776699029126 %\n",
      "\n",
      "threshold:  0.1\n",
      "SVM Accuracy: 74.82 %\n",
      "SVM imbalance (Positive rate): 4.247572815533981 %\n",
      "\n",
      "threshold:  0.11\n",
      "SVM Accuracy: 74.82 %\n",
      "SVM imbalance (Positive rate): 4.611650485436893 %\n",
      "\n",
      "threshold:  0.12\n",
      "SVM Accuracy: 74.45 %\n",
      "SVM imbalance (Positive rate): 4.733009708737864 %\n",
      "\n",
      "threshold:  0.13\n",
      "SVM Accuracy: 74.23 %\n",
      "SVM imbalance (Positive rate): 5.097087378640777 %\n",
      "\n",
      "threshold:  0.14\n",
      "SVM Accuracy: 74.09 %\n",
      "SVM imbalance (Positive rate): 5.461165048543689 %\n",
      "\n",
      "threshold:  0.15\n",
      "SVM Accuracy: 74.01 %\n",
      "SVM imbalance (Positive rate): 6.432038834951456 %\n",
      "\n",
      "threshold:  0.16\n",
      "SVM Accuracy: 73.72 %\n",
      "SVM imbalance (Positive rate): 7.281553398058252 %\n",
      "\n",
      "threshold:  0.17\n",
      "SVM Accuracy: 73.87 %\n",
      "SVM imbalance (Positive rate): 7.8883495145631075 %\n",
      "\n",
      "threshold:  0.18\n",
      "SVM Accuracy: 73.65 %\n",
      "SVM imbalance (Positive rate): 8.009708737864079 %\n",
      "\n",
      "threshold:  0.19\n",
      "SVM Accuracy: 73.21 %\n",
      "SVM imbalance (Positive rate): 8.37378640776699 %\n",
      "\n",
      "threshold:  0.2\n",
      "SVM Accuracy: 73.14 %\n",
      "SVM imbalance (Positive rate): 8.495145631067961 %\n",
      "\n",
      "threshold:  0.21\n",
      "SVM Accuracy: 72.99 %\n",
      "SVM imbalance (Positive rate): 9.223300970873787 %\n",
      "\n",
      "threshold:  0.22\n",
      "SVM Accuracy: 72.41 %\n",
      "SVM imbalance (Positive rate): 10.072815533980583 %\n",
      "\n",
      "threshold:  0.23\n",
      "SVM Accuracy: 72.04 %\n",
      "SVM imbalance (Positive rate): 10.436893203883495 %\n",
      "\n",
      "threshold:  0.24\n",
      "SVM Accuracy: 71.39 %\n",
      "SVM imbalance (Positive rate): 11.286407766990292 %\n",
      "\n",
      "threshold:  0.25\n",
      "SVM Accuracy: 71.09 %\n",
      "SVM imbalance (Positive rate): 12.257281553398059 %\n",
      "\n",
      "threshold:  0.26\n",
      "SVM Accuracy: 71.02 %\n",
      "SVM imbalance (Positive rate): 12.864077669902912 %\n",
      "\n",
      "threshold:  0.27\n",
      "SVM Accuracy: 70.66 %\n",
      "SVM imbalance (Positive rate): 13.349514563106796 %\n",
      "\n",
      "threshold:  0.28\n",
      "SVM Accuracy: 70.51 %\n",
      "SVM imbalance (Positive rate): 13.592233009708737 %\n",
      "\n",
      "threshold:  0.29\n",
      "SVM Accuracy: 69.93 %\n",
      "SVM imbalance (Positive rate): 14.077669902912621 %\n",
      "[[895 159]\n",
      " [253  63]]\n",
      "\n",
      "threshold:  0.3\n",
      "SVM Accuracy: 69.78 %\n",
      "SVM imbalance (Positive rate): 14.563106796116504 %\n",
      "\n",
      "threshold:  0.31\n",
      "SVM Accuracy: 69.27 %\n",
      "SVM imbalance (Positive rate): 15.169902912621358 %\n",
      "\n",
      "threshold:  0.32\n",
      "SVM Accuracy: 68.98 %\n",
      "SVM imbalance (Positive rate): 15.53398058252427 %\n",
      "\n",
      "threshold:  0.33\n",
      "SVM Accuracy: 68.69 %\n",
      "SVM imbalance (Positive rate): 16.14077669902913 %\n",
      "\n",
      "threshold:  0.34\n",
      "SVM Accuracy: 67.81 %\n",
      "SVM imbalance (Positive rate): 17.111650485436893 %\n",
      "\n",
      "threshold:  0.35000000000000003\n",
      "SVM Accuracy: 67.66 %\n",
      "SVM imbalance (Positive rate): 17.354368932038835 %\n",
      "\n",
      "threshold:  0.36\n",
      "SVM Accuracy: 66.93 %\n",
      "SVM imbalance (Positive rate): 17.96116504854369 %\n",
      "\n",
      "threshold:  0.37\n",
      "SVM Accuracy: 66.5 %\n",
      "SVM imbalance (Positive rate): 18.689320388349515 %\n",
      "\n",
      "threshold:  0.38\n",
      "SVM Accuracy: 66.5 %\n",
      "SVM imbalance (Positive rate): 19.296116504854368 %\n",
      "\n",
      "threshold:  0.39\n",
      "SVM Accuracy: 65.91 %\n",
      "SVM imbalance (Positive rate): 20.145631067961165 %\n",
      "\n",
      "threshold:  0.4\n",
      "SVM Accuracy: 65.47 %\n",
      "SVM imbalance (Positive rate): 20.75242718446602 %\n",
      "\n",
      "threshold:  0.41000000000000003\n",
      "SVM Accuracy: 64.96 %\n",
      "SVM imbalance (Positive rate): 21.2378640776699 %\n",
      "\n",
      "threshold:  0.42\n",
      "SVM Accuracy: 64.6 %\n",
      "SVM imbalance (Positive rate): 22.208737864077673 %\n",
      "\n",
      "threshold:  0.43\n",
      "SVM Accuracy: 64.23 %\n",
      "SVM imbalance (Positive rate): 23.42233009708738 %\n",
      "\n",
      "threshold:  0.44\n",
      "SVM Accuracy: 63.5 %\n",
      "SVM imbalance (Positive rate): 23.78640776699029 %\n",
      "\n",
      "threshold:  0.45\n",
      "SVM Accuracy: 63.5 %\n",
      "SVM imbalance (Positive rate): 24.87864077669903 %\n",
      "\n",
      "threshold:  0.46\n",
      "SVM Accuracy: 63.07 %\n",
      "SVM imbalance (Positive rate): 25.728155339805824 %\n",
      "\n",
      "threshold:  0.47000000000000003\n",
      "SVM Accuracy: 62.34 %\n",
      "SVM imbalance (Positive rate): 26.941747572815533 %\n",
      "\n",
      "threshold:  0.48\n",
      "SVM Accuracy: 62.19 %\n",
      "SVM imbalance (Positive rate): 28.398058252427184 %\n",
      "\n",
      "threshold:  0.49\n",
      "SVM Accuracy: 61.31 %\n",
      "SVM imbalance (Positive rate): 28.883495145631066 %\n",
      "\n",
      "threshold:  0.5\n",
      "SVM Accuracy: 60.22 %\n",
      "SVM imbalance (Positive rate): 29.61165048543689 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_pred_prob=svm_clf.predict_proba(validation_tweets_df_final)[:,0]\n",
    "for t in threshold:\n",
    "    svm_result=validation_sample.loc[:,['sentiment']]\n",
    "    svm_result['pred_sentiment']=np.where(svm_pred_prob>t,\"Negative\",\"Positive\")\n",
    "    svm_result_1=svm_result[svm_result.sentiment!='Neutral']\n",
    "    print(\"threshold: \",t)\n",
    "    c=0\n",
    "    for i in range(svm_result_1.shape[0]):\n",
    "        if svm_result_1.sentiment.iloc[i]==svm_result_1.pred_sentiment.iloc[i]:\n",
    "            c+=1\n",
    "    print('SVM Accuracy:',round(c*100/svm_result_1.shape[0],2),'%')\n",
    "    svm_result_2=svm_result[svm_result.sentiment=='Neutral']\n",
    "    print('SVM imbalance (Positive rate):', Counter(svm_result_2.pred_sentiment)['Positive']/svm_result_2.shape[0]*100, '%')\n",
    "    if t==0.29:\n",
    "        print(confusion_matrix(svm_result_1.iloc[:,0],svm_result_1.iloc[:,1]))\n",
    "    print('')\n",
    "#svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### - Evaluate the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_pred=lr_clf.predict(validation_tweets_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_result=validation_sample.loc[:,['sentiment']]\n",
    "lr_result['pred_sentiment']=lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy: 39.05 %\n"
     ]
    }
   ],
   "source": [
    "lr_result_1=lr_result[lr_result.sentiment!='Neutral']\n",
    "c=0\n",
    "for i in range(lr_result_1.shape[0]):\n",
    "    if lr_result_1.sentiment.iloc[i]==lr_result_1.pred_sentiment.iloc[i]:\n",
    "        c+=1\n",
    "print('LR Accuracy:',round(c*100/lr_result_1.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR imbalance (Positive rate): 73.30097087378641 %\n"
     ]
    }
   ],
   "source": [
    "lr_result_2=lr_result[lr_result.sentiment=='Neutral']\n",
    "print('LR imbalance (Positive rate):', Counter(lr_result_2.pred_sentiment)['Positive']/lr_result_2.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[292, 762],\n",
       "       [ 73, 243]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(lr_result_1.iloc[:,0],lr_result_1.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14816387,  0.21407164,  0.55348139, ...,  0.49612704,\n",
       "        0.53752547,  0.59540195])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.predict_proba(validation_tweets_df_final)[:,0] #it's predicting the probability of negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.0\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.0 %\n",
      "\n",
      "threshold:  0.01\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.02\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.03\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.04\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.05\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.06\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.07\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.08\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.09\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.1\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.11\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.12\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.13\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.14\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.15\n",
      "LR Accuracy: 77.08 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.16\n",
      "LR Accuracy: 77.08 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.17\n",
      "LR Accuracy: 77.08 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.18\n",
      "LR Accuracy: 77.08 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.19\n",
      "LR Accuracy: 77.08 %\n",
      "LR imbalance (Positive rate): 0.24271844660194172 %\n",
      "\n",
      "threshold:  0.2\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.3640776699029126 %\n",
      "\n",
      "threshold:  0.21\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.3640776699029126 %\n",
      "\n",
      "threshold:  0.22\n",
      "LR Accuracy: 76.93 %\n",
      "LR imbalance (Positive rate): 0.48543689320388345 %\n",
      "\n",
      "threshold:  0.23\n",
      "LR Accuracy: 77.01 %\n",
      "LR imbalance (Positive rate): 0.6067961165048543 %\n",
      "\n",
      "threshold:  0.24\n",
      "LR Accuracy: 76.86 %\n",
      "LR imbalance (Positive rate): 0.7281553398058253 %\n",
      "\n",
      "threshold:  0.25\n",
      "LR Accuracy: 77.15 %\n",
      "LR imbalance (Positive rate): 0.9708737864077669 %\n",
      "\n",
      "threshold:  0.26\n",
      "LR Accuracy: 77.45 %\n",
      "LR imbalance (Positive rate): 1.5776699029126213 %\n",
      "\n",
      "threshold:  0.27\n",
      "LR Accuracy: 77.3 %\n",
      "LR imbalance (Positive rate): 2.063106796116505 %\n",
      "\n",
      "threshold:  0.28\n",
      "LR Accuracy: 77.01 %\n",
      "LR imbalance (Positive rate): 2.7912621359223304 %\n",
      "\n",
      "threshold:  0.29\n",
      "LR Accuracy: 76.64 %\n",
      "LR imbalance (Positive rate): 3.1553398058252426 %\n",
      "\n",
      "threshold:  0.3\n",
      "LR Accuracy: 76.35 %\n",
      "LR imbalance (Positive rate): 3.640776699029126 %\n",
      "\n",
      "threshold:  0.31\n",
      "LR Accuracy: 76.72 %\n",
      "LR imbalance (Positive rate): 4.0048543689320395 %\n",
      "\n",
      "threshold:  0.32\n",
      "LR Accuracy: 76.64 %\n",
      "LR imbalance (Positive rate): 5.097087378640777 %\n",
      "\n",
      "threshold:  0.33\n",
      "LR Accuracy: 75.77 %\n",
      "LR imbalance (Positive rate): 6.067961165048544 %\n",
      "\n",
      "threshold:  0.34\n",
      "LR Accuracy: 75.26 %\n",
      "LR imbalance (Positive rate): 8.009708737864079 %\n",
      "\n",
      "threshold:  0.35000000000000003\n",
      "LR Accuracy: 74.89 %\n",
      "LR imbalance (Positive rate): 9.344660194174757 %\n",
      "\n",
      "threshold:  0.36\n",
      "LR Accuracy: 73.8 %\n",
      "LR imbalance (Positive rate): 11.286407766990292 %\n",
      "\n",
      "threshold:  0.37\n",
      "LR Accuracy: 73.28 %\n",
      "LR imbalance (Positive rate): 12.62135922330097 %\n",
      "\n",
      "threshold:  0.38\n",
      "LR Accuracy: 72.34 %\n",
      "LR imbalance (Positive rate): 15.169902912621358 %\n",
      "\n",
      "threshold:  0.39\n",
      "LR Accuracy: 71.39 %\n",
      "LR imbalance (Positive rate): 17.96116504854369 %\n",
      "\n",
      "threshold:  0.4\n",
      "LR Accuracy: 69.71 %\n",
      "LR imbalance (Positive rate): 20.509708737864077 %\n",
      "[[845 209]\n",
      " [206 110]]\n",
      "\n",
      "threshold:  0.41000000000000003\n",
      "LR Accuracy: 67.81 %\n",
      "LR imbalance (Positive rate): 23.78640776699029 %\n",
      "\n",
      "threshold:  0.42\n",
      "LR Accuracy: 65.04 %\n",
      "LR imbalance (Positive rate): 27.305825242718445 %\n",
      "\n",
      "threshold:  0.43\n",
      "LR Accuracy: 61.46 %\n",
      "LR imbalance (Positive rate): 31.6747572815534 %\n",
      "\n",
      "threshold:  0.44\n",
      "LR Accuracy: 57.08 %\n",
      "LR imbalance (Positive rate): 41.50485436893204 %\n",
      "\n",
      "threshold:  0.45\n",
      "LR Accuracy: 51.46 %\n",
      "LR imbalance (Positive rate): 55.46116504854369 %\n",
      "\n",
      "threshold:  0.46\n",
      "LR Accuracy: 49.12 %\n",
      "LR imbalance (Positive rate): 60.55825242718447 %\n",
      "\n",
      "threshold:  0.47000000000000003\n",
      "LR Accuracy: 46.2 %\n",
      "LR imbalance (Positive rate): 63.3495145631068 %\n",
      "\n",
      "threshold:  0.48\n",
      "LR Accuracy: 43.43 %\n",
      "LR imbalance (Positive rate): 67.59708737864078 %\n",
      "\n",
      "threshold:  0.49\n",
      "LR Accuracy: 40.95 %\n",
      "LR imbalance (Positive rate): 70.3883495145631 %\n",
      "\n",
      "threshold:  0.5\n",
      "LR Accuracy: 39.05 %\n",
      "LR imbalance (Positive rate): 73.30097087378641 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pred_prob=lr_clf.predict_proba(validation_tweets_df_final)[:,0]\n",
    "for t in threshold:\n",
    "    lr_result=validation_sample.loc[:,['sentiment']]\n",
    "    lr_result['pred_sentiment']=np.where(lr_pred_prob>t,\"Negative\",\"Positive\")\n",
    "    lr_result_1=lr_result[lr_result.sentiment!='Neutral']\n",
    "    print(\"threshold: \",t)\n",
    "    c=0\n",
    "    for i in range(lr_result_1.shape[0]):\n",
    "        if lr_result_1.sentiment.iloc[i]==lr_result_1.pred_sentiment.iloc[i]:\n",
    "            c+=1\n",
    "    print('LR Accuracy:',round(c*100/lr_result_1.shape[0],2),'%')\n",
    "    lr_result_2=lr_result[lr_result.sentiment=='Neutral']\n",
    "    print('LR imbalance (Positive rate):', Counter(lr_result_2.pred_sentiment)['Positive']/lr_result_2.shape[0]*100, '%')\n",
    "    if round(t,2)==0.4:\n",
    "        print(confusion_matrix(lr_result_1.iloc[:,0],lr_result_1.iloc[:,1]))\n",
    "    print('')\n",
    "#svm_result['pred_sentiment']=svm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Train a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit(tweets_df_clean, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Evaluate the Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_pred=nb_clf.predict(validation_tweets_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_result=validation_sample.loc[:,['sentiment']]\n",
    "nb_result['pred_sentiment']=nb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Accuracy: 51.97 %\n"
     ]
    }
   ],
   "source": [
    "nb_result_1=nb_result[nb_result.sentiment!='Neutral']\n",
    "c=0\n",
    "for i in range(nb_result_1.shape[0]):\n",
    "    if nb_result_1.sentiment.iloc[i]==nb_result_1.pred_sentiment.iloc[i]:\n",
    "        c+=1\n",
    "print('NB Accuracy:',round(c*100/nb_result_1.shape[0],2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB imbalance (Positive rate): 64.92718446601941 %\n"
     ]
    }
   ],
   "source": [
    "nb_result_2=nb_result[nb_result.sentiment=='Neutral']\n",
    "print('NB imbalance (Positive rate):', Counter(nb_result_2.pred_sentiment)['Positive']/nb_result_2.shape[0]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[473, 581],\n",
       "       [ 77, 239]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(nb_result_1.iloc[:,0],nb_result_1.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.0\n",
      "NB Accuracy: 76.93 %\n",
      "NB imbalance (Positive rate): 0.0 %\n",
      "\n",
      "threshold:  0.01\n",
      "NB Accuracy: 77.3 %\n",
      "NB imbalance (Positive rate): 1.0922330097087378 %\n",
      "\n",
      "threshold:  0.02\n",
      "NB Accuracy: 77.66 %\n",
      "NB imbalance (Positive rate): 2.1844660194174756 %\n",
      "\n",
      "threshold:  0.03\n",
      "NB Accuracy: 77.01 %\n",
      "NB imbalance (Positive rate): 3.762135922330097 %\n",
      "\n",
      "threshold:  0.04\n",
      "NB Accuracy: 76.57 %\n",
      "NB imbalance (Positive rate): 6.310679611650485 %\n",
      "\n",
      "threshold:  0.05\n",
      "NB Accuracy: 76.13 %\n",
      "NB imbalance (Positive rate): 8.37378640776699 %\n",
      "\n",
      "threshold:  0.06\n",
      "NB Accuracy: 75.91 %\n",
      "NB imbalance (Positive rate): 9.466019417475728 %\n",
      "\n",
      "threshold:  0.07\n",
      "NB Accuracy: 75.33 %\n",
      "NB imbalance (Positive rate): 11.286407766990292 %\n",
      "\n",
      "threshold:  0.08\n",
      "NB Accuracy: 74.89 %\n",
      "NB imbalance (Positive rate): 12.62135922330097 %\n",
      "\n",
      "threshold:  0.09\n",
      "NB Accuracy: 75.04 %\n",
      "NB imbalance (Positive rate): 13.95631067961165 %\n",
      "\n",
      "threshold:  0.1\n",
      "NB Accuracy: 74.6 %\n",
      "NB imbalance (Positive rate): 15.291262135922329 %\n",
      "\n",
      "threshold:  0.11\n",
      "NB Accuracy: 74.45 %\n",
      "NB imbalance (Positive rate): 15.776699029126215 %\n",
      "\n",
      "threshold:  0.12\n",
      "NB Accuracy: 74.16 %\n",
      "NB imbalance (Positive rate): 17.475728155339805 %\n",
      "\n",
      "threshold:  0.13\n",
      "NB Accuracy: 73.43 %\n",
      "NB imbalance (Positive rate): 18.567961165048544 %\n",
      "\n",
      "threshold:  0.14\n",
      "NB Accuracy: 73.28 %\n",
      "NB imbalance (Positive rate): 19.902912621359224 %\n",
      "\n",
      "threshold:  0.15\n",
      "NB Accuracy: 72.92 %\n",
      "NB imbalance (Positive rate): 21.35922330097087 %\n",
      "\n",
      "threshold:  0.16\n",
      "NB Accuracy: 71.97 %\n",
      "NB imbalance (Positive rate): 22.936893203883496 %\n",
      "\n",
      "threshold:  0.17\n",
      "NB Accuracy: 70.88 %\n",
      "NB imbalance (Positive rate): 24.271844660194176 %\n",
      "\n",
      "threshold:  0.18\n",
      "NB Accuracy: 70.29 %\n",
      "NB imbalance (Positive rate): 25.728155339805824 %\n",
      "\n",
      "threshold:  0.19\n",
      "NB Accuracy: 70.0 %\n",
      "NB imbalance (Positive rate): 26.820388349514563 %\n",
      "[[833 221]\n",
      " [190 126]]\n",
      "\n",
      "threshold:  0.2\n",
      "NB Accuracy: 69.71 %\n",
      "NB imbalance (Positive rate): 27.9126213592233 %\n",
      "\n",
      "threshold:  0.21\n",
      "NB Accuracy: 69.34 %\n",
      "NB imbalance (Positive rate): 29.247572815533978 %\n",
      "\n",
      "threshold:  0.22\n",
      "NB Accuracy: 69.12 %\n",
      "NB imbalance (Positive rate): 30.097087378640776 %\n",
      "\n",
      "threshold:  0.23\n",
      "NB Accuracy: 68.61 %\n",
      "NB imbalance (Positive rate): 30.8252427184466 %\n",
      "\n",
      "threshold:  0.24\n",
      "NB Accuracy: 67.74 %\n",
      "NB imbalance (Positive rate): 31.917475728155342 %\n",
      "\n",
      "threshold:  0.25\n",
      "NB Accuracy: 66.5 %\n",
      "NB imbalance (Positive rate): 33.859223300970875 %\n",
      "\n",
      "threshold:  0.26\n",
      "NB Accuracy: 65.04 %\n",
      "NB imbalance (Positive rate): 35.55825242718447 %\n",
      "\n",
      "threshold:  0.27\n",
      "NB Accuracy: 64.23 %\n",
      "NB imbalance (Positive rate): 37.13592233009709 %\n",
      "\n",
      "threshold:  0.28\n",
      "NB Accuracy: 63.36 %\n",
      "NB imbalance (Positive rate): 38.83495145631068 %\n",
      "\n",
      "threshold:  0.29\n",
      "NB Accuracy: 62.55 %\n",
      "NB imbalance (Positive rate): 39.56310679611651 %\n",
      "\n",
      "threshold:  0.3\n",
      "NB Accuracy: 62.63 %\n",
      "NB imbalance (Positive rate): 40.29126213592233 %\n",
      "\n",
      "threshold:  0.31\n",
      "NB Accuracy: 62.04 %\n",
      "NB imbalance (Positive rate): 41.140776699029125 %\n",
      "\n",
      "threshold:  0.32\n",
      "NB Accuracy: 61.75 %\n",
      "NB imbalance (Positive rate): 41.99029126213592 %\n",
      "\n",
      "threshold:  0.33\n",
      "NB Accuracy: 61.46 %\n",
      "NB imbalance (Positive rate): 42.23300970873786 %\n",
      "\n",
      "threshold:  0.34\n",
      "NB Accuracy: 60.73 %\n",
      "NB imbalance (Positive rate): 43.3252427184466 %\n",
      "\n",
      "threshold:  0.35000000000000003\n",
      "NB Accuracy: 58.98 %\n",
      "NB imbalance (Positive rate): 50.8495145631068 %\n",
      "\n",
      "threshold:  0.36\n",
      "NB Accuracy: 58.32 %\n",
      "NB imbalance (Positive rate): 51.334951456310684 %\n",
      "\n",
      "threshold:  0.37\n",
      "NB Accuracy: 57.81 %\n",
      "NB imbalance (Positive rate): 52.79126213592234 %\n",
      "\n",
      "threshold:  0.38\n",
      "NB Accuracy: 57.3 %\n",
      "NB imbalance (Positive rate): 53.640776699029125 %\n",
      "\n",
      "threshold:  0.39\n",
      "NB Accuracy: 56.93 %\n",
      "NB imbalance (Positive rate): 54.12621359223301 %\n",
      "\n",
      "threshold:  0.4\n",
      "NB Accuracy: 56.57 %\n",
      "NB imbalance (Positive rate): 55.21844660194175 %\n",
      "\n",
      "threshold:  0.41000000000000003\n",
      "NB Accuracy: 55.69 %\n",
      "NB imbalance (Positive rate): 55.582524271844655 %\n",
      "\n",
      "threshold:  0.42\n",
      "NB Accuracy: 55.62 %\n",
      "NB imbalance (Positive rate): 56.067961165048544 %\n",
      "\n",
      "threshold:  0.43\n",
      "NB Accuracy: 55.33 %\n",
      "NB imbalance (Positive rate): 57.76699029126213 %\n",
      "\n",
      "threshold:  0.44\n",
      "NB Accuracy: 54.89 %\n",
      "NB imbalance (Positive rate): 58.859223300970875 %\n",
      "\n",
      "threshold:  0.45\n",
      "NB Accuracy: 54.53 %\n",
      "NB imbalance (Positive rate): 59.70873786407766 %\n",
      "\n",
      "threshold:  0.46\n",
      "NB Accuracy: 53.72 %\n",
      "NB imbalance (Positive rate): 60.922330097087375 %\n",
      "\n",
      "threshold:  0.47000000000000003\n",
      "NB Accuracy: 53.28 %\n",
      "NB imbalance (Positive rate): 62.01456310679612 %\n",
      "\n",
      "threshold:  0.48\n",
      "NB Accuracy: 52.99 %\n",
      "NB imbalance (Positive rate): 63.228155339805824 %\n",
      "\n",
      "threshold:  0.49\n",
      "NB Accuracy: 52.26 %\n",
      "NB imbalance (Positive rate): 64.44174757281553 %\n",
      "\n",
      "threshold:  0.5\n",
      "NB Accuracy: 51.97 %\n",
      "NB imbalance (Positive rate): 64.92718446601941 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_pred_prob=nb_clf.predict_proba(validation_tweets_df_final)[:,0]\n",
    "for t in threshold:\n",
    "    nb_result=validation_sample.loc[:,['sentiment']]\n",
    "    nb_result['pred_sentiment']=np.where(nb_pred_prob>t,\"Negative\",\"Positive\")\n",
    "    nb_result_1=nb_result[nb_result.sentiment!='Neutral']\n",
    "    print(\"threshold: \",t)\n",
    "    c=0\n",
    "    for i in range(nb_result_1.shape[0]):\n",
    "        if nb_result_1.sentiment.iloc[i]==nb_result_1.pred_sentiment.iloc[i]:\n",
    "            c+=1\n",
    "    print('NB Accuracy:',round(c*100/nb_result_1.shape[0],2),'%')\n",
    "    nb_result_2=nb_result[nb_result.sentiment=='Neutral']\n",
    "    print('NB imbalance (Positive rate):', Counter(nb_result_2.pred_sentiment)['Positive']/nb_result_2.shape[0]*100, '%')\n",
    "    if t==0.19:\n",
    "        print(confusion_matrix(nb_result_1.iloc[:,0],nb_result_1.iloc[:,1]))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
